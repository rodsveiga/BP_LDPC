{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding with Belief Propagation\n",
    "\n",
    "We want to iterate the following the following equations:\n",
    "\n",
    "$$ \\hat{m}_{\\mu j} = \\tanh ( \\beta(\\rho) J_\\mu ) \\prod_{ l \\in {\\cal L} (\\mu) \\backslash j } m_{\\mu l}  \\; \\; ,  $$ \n",
    "\n",
    "$$ m_{\\mu j} = \\tanh \\left(  \\sum_{ \\nu \\in {\\cal M} (j) \\backslash \\mu } \\ \\tanh^{-1} \\left(  \\hat{m}_{\\nu j}  \\right)     \\right) + \\beta(\\rho_\\xi)  \\; \\; ,  $$  \n",
    "\n",
    "which are Eqs.(96) from the paper [Low-density parity-check codesâ€”A statistical physics perspective](https://www.sciencedirect.com/science/article/pii/S1076567002800180), by R. Vicente, D. Saad and Y. Kabashima.\n",
    "\n",
    "The function $ \\beta(x) $ is the Nishimori temperature,\n",
    "\n",
    "$$ \\beta(x) = \\frac{1}{2} \\log \\left(  \\frac{1- \\rho}{\\rho}  \\right) \\; \\; .  $$\n",
    "\n",
    "The quantity $\\rho$ is the flip probablility of the noisy channel (BSC),\n",
    "\n",
    "$$ P ( J | J^{(0)} ) = (1 - \\rho) \\delta_{J, J^{(0)} } + \\rho \\delta_{J, -J^{(0)} }   \\; \\; , $$\n",
    "\n",
    "whereas the prior distribution for each meassage bit is assumed to be\n",
    "\n",
    "$$ P ( S_j ) = (1 - \\rho_\\xi) \\delta_{+1, S_j }  +  \\rho_\\xi \\delta_{-1, S_j }  \\; \\; .  $$\n",
    "\n",
    "The object $ {\\cal L} (\\mu)$ represents the set of $K$ non-zero elements on the row $\\mu$ of the code generator matrix ${\\cal G}$ (the one which adds redundancy), \n",
    "\n",
    "$$  {\\cal L} (\\mu) = \\langle i_1, i_2, ..., i_K \\rangle  \\; \\; .  $$\n",
    "\n",
    "The are $C$ non-zero elements per column on the matrix ${\\cal G}$:\n",
    "\n",
    "$$ \\sum_{\\mu : j \\in {\\cal L}(\\mu)} i_j = C \\; \\; ; \\; \\; \\forall j = 1, ..., K \\; \\; . $$\n",
    "\n",
    "The object $ {\\cal M} (j)$ represents the set of all index sets that contain $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the variables of the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message lengh\n",
    "N = 100\n",
    "\n",
    "# Codeword lengh\n",
    "M = 200\n",
    "\n",
    "# Non-zero elements per row of the generation matrix\n",
    "K = 4\n",
    "\n",
    "# Number of messages\n",
    "n = 10\n",
    "\n",
    "# Noisy channel\n",
    "p = 0.3\n",
    "beta = 0.5*np.log( (1 - p) / p)\n",
    "\n",
    "# Message prior\n",
    "p_prior = 0.1\n",
    "beta_prior = 0.5*np.log( (1 - p_prior) / p_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating messages\n",
    "\n",
    "Each message is a $N$ dimensional vector. Generate a set of $n$ messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = torch.rand([n, N])\n",
    "    \n",
    "message = torch.zeros([n, N])\n",
    "\n",
    "for j in range(random.shape[0]):\n",
    "    \n",
    "    for k in range(random.shape[1]):\n",
    "               \n",
    "            #### -1 with probability p_prior\n",
    "            if random[j,k] <= p_prior:\n",
    "                message[j,k] = -1.\n",
    "            #### +1 with probability 1 - p_prior\n",
    "            else:\n",
    "                message[j,k] = +1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each message is encoded to a high dimensional vector ${\\bf J}^{(0)} \\in \\{ \\pm 1  \\}^M$ defined as \n",
    "\n",
    "$$   J^{(0)}_{\\langle i_1, i_2, ...., i_K \\rangle} = \\xi_1 \\xi_ 2 ... \\xi_K  \\; \\; ,$$\n",
    "\n",
    "where $M$ sets of $K \\in [ 1, ..., N]$ indexes are randomly chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = torch.randint(0, N, [M, K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 4])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From `encoding`, we construct the encoded message ${\\bf J}^{(0)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(message.shape[0]):\n",
    "    \n",
    "    J0 = torch.take(message[j], encoding).prod(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing\n",
    "J0 = torch.take(message[0], encoding).prod(dim=1)\n",
    "J0 = J0.unsqueeze(0)\n",
    "\n",
    "for j in range(1, message.shape[0]):\n",
    "    \n",
    "    J0_ = torch.take(message[j], encoding).prod(dim=1)\n",
    "    J0_ = J0_.unsqueeze(0)\n",
    "    \n",
    "    J0 = torch.cat((J0, J0_), dim= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the corrupted version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = J0.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = torch.rand(J.shape)\n",
    "                      \n",
    "for j in range(J.shape[0]):\n",
    "    for k in range(J.shape[1]):\n",
    "          \n",
    "        if random[j, k] <= p:\n",
    "            J[j, k] = -J[j, k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us focus in one received message to iterate the belief propagation equations.\n",
    "\n",
    "$$ \\hat{m}_{\\mu j} = \\tanh ( \\beta(\\rho) J_\\mu ) \\prod_{ l \\in {\\cal L} (\\mu) \\backslash j } m_{\\mu l}  \\; \\; ,  $$ \n",
    "\n",
    "$$ m_{\\mu j} = \\tanh \\left(  \\sum_{ \\nu \\in {\\cal M} (j) \\backslash \\mu} \\ \\tanh^{-1} \\left(  \\hat{m}_{\\nu j}  \\right)     \\right) + \\beta(\\rho_\\xi)  \\; \\; ,  $$  \n",
    "\n",
    "with $j = 1, ..., N$ and $\\mu = 1, ..., M$.\n",
    "\n",
    "We cal this message `J_`. We will worry later about a loop over all the received messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
      "         1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        -1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,\n",
      "         1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,\n",
      "         1.,  1., -1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.,  1.,\n",
      "         1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
      "         1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,\n",
      "         1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,\n",
      "         1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,\n",
      "         1., -1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,\n",
      "        -1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.,  1., -1.,\n",
      "         1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.,\n",
      "         1.,  1.,  1.,  1.])\n",
      "torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "J_ = J[0]\n",
    "print(J_)\n",
    "print(J_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random initialization of the beliefs $m_{\\mu l}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.rand(M, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5737, 0.3259, 0.1629,  ..., 0.5391, 0.5564, 0.4237],\n",
       "        [0.8206, 0.2177, 0.8888,  ..., 0.0783, 0.1224, 0.3776],\n",
       "        [0.6112, 0.9259, 0.9299,  ..., 0.8411, 0.8729, 0.6649],\n",
       "        ...,\n",
       "        [0.5682, 0.4077, 0.6779,  ..., 0.6039, 0.6576, 0.7261],\n",
       "        [0.2614, 0.4347, 0.6711,  ..., 0.1953, 0.9119, 0.3932],\n",
       "        [0.4544, 0.2197, 0.0443,  ..., 0.8243, 0.3393, 0.3847]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize an empty tensor to represent $\\hat{m}_{\\mu l}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_hat = torch.empty(M, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to calculate $\\hat{m}_{\\mu j}$.\n",
    "\n",
    "$$ \\hat{m}_{\\mu j} = \\tanh ( \\beta(\\rho) J_\\mu ) \\prod_{ l \\in {\\cal L} (\\mu) \\backslash j } m_{\\mu l}  \\; \\; ,  $$ \n",
    "\n",
    "This first implementation has two `for` loops. This is potentially harmful if one cares about efficienty. We obviously do, but since we are just beginning, lets go on like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mu in range(M):\n",
    "    for j in range(N):\n",
    "          \n",
    "        # Keep only L(mu) which a are different of j\n",
    "        index_no_j = torch.nonzero(encoding[mu] != j).squeeze()\n",
    "        L_no_j = encoding[mu][index_no_j]\n",
    "        \n",
    "        # Message update        \n",
    "        m_hat[mu, j] = torch.tanh( beta* J_[mu])*torch.take(m[mu], L_no_j).prod(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.2171e-06,  5.2171e-06,  5.2171e-06,  ...,  5.2171e-06,\n",
       "          5.2171e-06,  5.2171e-06],\n",
       "        [ 2.0069e-02,  2.0069e-02,  2.0069e-02,  ...,  2.0069e-02,\n",
       "          2.0069e-02,  2.0069e-02],\n",
       "        [-2.1374e-02, -2.1374e-02, -2.1374e-02,  ..., -2.1374e-02,\n",
       "         -2.1374e-02, -2.1374e-02],\n",
       "        ...,\n",
       "        [ 1.1966e-03,  1.1966e-03,  1.1966e-03,  ...,  1.1966e-03,\n",
       "          1.1966e-03,  1.1966e-03],\n",
       "        [ 2.8509e-03,  2.8509e-03,  2.8509e-03,  ...,  2.8509e-03,\n",
       "          2.8509e-03,  2.8509e-03],\n",
       "        [ 1.1827e-02,  1.1827e-02,  1.1827e-02,  ...,  1.4347e-02,\n",
       "          1.1827e-02,  1.1827e-02]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to implement:\n",
    "\n",
    "$$ m_{\\mu j} = \\tanh \\left(  \\sum_{ \\nu \\in {\\cal M} (j) \\backslash \\mu} \\ \\tanh^{-1} \\left(  \\hat{m}_{\\nu j}  \\right)     \\right) + \\beta(\\rho_\\xi)  \\; \\; ,  $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(N):\n",
    "    \n",
    "    for mu in range(M):\n",
    "        \n",
    "        M_set = torch.where(encoding == j)[0]\n",
    "        \n",
    "        M_set_no_mu = M_set[torch.nonzero(M_set != mu).squeeze()]\n",
    "        \n",
    "        #print(np.arctanh(m_hat[:, j]))\n",
    "        \n",
    "        m[mu, j] = torch.tanh(torch.take(np.arctanh(m_hat[:, j]), M_set_no_mu).sum() + beta_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8080, 0.6590, 0.7828,  ..., 0.9041, 0.6813, 0.7584],\n",
       "        [0.8080, 0.6590, 0.7828,  ..., 0.9041, 0.6813, 0.7584],\n",
       "        [0.8080, 0.6590, 0.7828,  ..., 0.9041, 0.6813, 0.7584],\n",
       "        ...,\n",
       "        [0.8080, 0.6590, 0.7828,  ..., 0.9041, 0.6813, 0.7584],\n",
       "        [0.8080, 0.6590, 0.7828,  ..., 0.9041, 0.6813, 0.7584],\n",
       "        [0.8080, 0.6590, 0.7828,  ..., 0.9014, 0.6813, 0.7584]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 16,  18,  38,  51,  59, 110, 142, 146, 149, 168, 169, 175, 185, 190])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(encoding == 12)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.9573e+00,  1.3855e+00,  1.9028e-01, -1.7844e+00,  5.0827e-01,\n",
      "         3.8991e-01, -3.3806e-02,  6.4215e-01, -1.0100e-01,  5.0615e-01,\n",
      "        -3.0457e-01,  4.5092e-01,  6.5737e-01, -2.0985e+00,  8.0717e-01,\n",
      "         1.1149e+00, -6.9266e-02,  7.7242e-02, -1.3143e+00, -1.1171e+00,\n",
      "         3.2288e-01, -6.8386e-01, -8.5211e-01, -9.8985e-01,  1.2180e+00,\n",
      "        -4.7351e-01, -1.2878e-01, -6.0639e-01, -2.6454e-01, -2.1705e+00,\n",
      "        -1.4315e+00, -2.4212e+00,  6.0035e-01,  1.3754e+00,  6.0277e-01,\n",
      "        -1.8355e+00,  4.7591e-01,  1.2254e+00,  2.3661e+00, -7.6653e-01,\n",
      "        -1.5692e+00, -1.0605e+00, -6.7472e-01,  4.5668e-01, -1.6376e+00,\n",
      "        -3.0720e-01, -5.6713e-01, -1.0771e-01, -1.8200e+00,  5.5905e-01,\n",
      "         7.9153e-01,  2.1574e+00, -1.1527e+00,  6.0929e-01,  2.0709e+00,\n",
      "        -6.2848e-01,  1.1242e+00,  6.9097e-01, -9.8604e-01,  3.9571e-01,\n",
      "        -2.1559e+00,  1.5495e+00,  6.5942e-01, -6.2958e-01,  1.8700e+00,\n",
      "         6.6519e-01,  1.1562e+00, -2.7643e-01, -6.4465e-01, -1.0191e+00,\n",
      "        -9.8628e-01, -1.4544e+00,  1.5518e-01,  6.4411e-01,  1.5497e+00,\n",
      "        -9.2737e-01, -5.1013e-01,  5.7420e-01,  1.5452e-01, -4.7275e-01,\n",
      "         7.2715e-01, -1.8799e+00, -1.2084e+00,  1.7179e+00, -8.3212e-01,\n",
      "         3.5145e-01, -9.7202e-01, -1.4783e+00, -2.0007e+00, -4.3340e-01,\n",
      "        -9.7069e-01,  5.3541e-01,  5.3986e-01, -1.0947e+00, -2.3709e-01,\n",
      "        -4.6842e-01,  7.8057e-01, -2.4774e-01,  1.1380e-02,  1.2101e+00,\n",
      "        -2.7913e-01,  6.5561e-01, -9.9985e-01,  3.6840e-01,  1.0544e+00,\n",
      "         2.0914e+00,  3.8500e-01,  2.8629e-01, -1.1318e+00,  1.1419e+00,\n",
      "         3.4850e-01,  2.4993e-01,  1.5683e+00,  2.3057e-02, -7.2642e-01,\n",
      "         5.8756e-01,  9.3776e-03,  1.5209e-01,  4.2331e-04, -1.1296e+00,\n",
      "        -1.4123e+00, -3.0469e-02, -5.8692e-01, -7.4063e-01,  1.8469e-03,\n",
      "        -1.7606e-01,  5.3259e-01,  2.8528e-01,  2.7714e-01,  4.0681e-01,\n",
      "        -3.7991e-01,  1.3800e+00, -2.9620e-01,  5.4288e-02, -9.3883e-02,\n",
      "        -1.4068e+00,  8.5590e-01,  1.3474e+00, -8.4725e-01,  1.4947e+00,\n",
      "        -4.7221e-01, -1.9023e-01, -1.0765e-01,  1.6122e+00, -2.2822e+00,\n",
      "        -4.5940e-01, -7.2180e-02, -4.0896e-02, -3.3468e-01,  5.9569e-01,\n",
      "         1.6719e+00,  1.0557e+00, -7.5802e-01, -4.5426e-01,  1.8543e-01,\n",
      "        -1.1445e+00, -3.0023e-01,  1.5190e+00,  3.3211e-01, -9.9488e-01,\n",
      "        -1.3756e+00, -5.0548e-01, -9.7193e-01, -1.4549e-01, -9.0858e-01,\n",
      "        -3.3058e-01,  7.9153e-02, -1.9876e-01,  9.1888e-01,  1.0211e-01,\n",
      "         1.1407e-01,  1.2287e+00,  8.7667e-02, -1.0957e+00, -1.2787e-01,\n",
      "        -1.5468e+00, -2.4578e-01,  2.4930e-01,  8.4268e-01, -9.5811e-02,\n",
      "         1.9571e+00, -4.4444e-01, -1.2451e+00,  9.9219e-01,  1.3245e+00,\n",
      "        -1.2987e+00,  1.4804e+00,  2.3206e-01,  1.0828e+00, -2.4953e+00,\n",
      "         1.1145e+00,  1.0327e+00, -5.7275e-01,  2.0537e+00,  3.8566e-01,\n",
      "        -1.1650e+00,  1.7855e+00,  7.4680e-01,  1.1743e+00,  5.6399e-01])\n",
      "torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "m_hat0 = m[:, 0]\n",
    "print(m_hat0)\n",
    "print(m_hat0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 19,  25,  41,  77,  81, 110, 118, 135, 135, 142, 177, 192])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_ = torch.where(encoding == 0)[0]\n",
    "M_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 19,  25,  41,  77,  81, 110, 118, 135, 135, 142, 177, 192])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(M_ != 19).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 25,  41,  77,  81, 110, 118, 135, 135, 142, 177, 192])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_[torch.nonzero(M_ != 19).squeeze()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_set_no = M_[torch.nonzero(M_ != 19).squeeze()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 25,  41,  77,  81, 110, 118, 135, 135, 142, 177, 192])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_set_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0440)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.take(m_hat[:, 0], M_set_no_mu).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 3])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_less = encoding[0][prod_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 98, 58])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6863)\n",
      "tensor(0.4078)\n",
      "tensor(1.2403)\n"
     ]
    }
   ],
   "source": [
    "print(m[0][5])\n",
    "print(m[0][98])\n",
    "print(m[0][58])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3471)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.take(m[0], L_less).prod(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(encoding[0] != 60).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(60)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5],\n",
       "        [98],\n",
       "        [58]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding[0][torch.nonzero(encoding[0] != 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding[0][torch.nonzero(encoding[0] != 60)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 4, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoding[0])\n",
    "print(m[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([66, 31, 39, 22])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
      "         1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        -1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,\n",
      "         1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,\n",
      "         1.,  1., -1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.,  1.,\n",
      "         1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
      "         1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,\n",
      "         1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,\n",
      "         1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,\n",
      "         1., -1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,\n",
      "        -1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.,  1., -1.,\n",
      "         1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.,\n",
      "         1.,  1.,  1.,  1.])\n",
      "torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "print(J_)\n",
    "print(J_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_full = torch.take(m[0], encoding).prod(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False,  True, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False,  True, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [ True, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False,  True, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False,  True, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False,  True, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 28,   2],\n",
       "        [ 91,   2],\n",
       "        [119,   3],\n",
       "        [130,   0],\n",
       "        [168,   1],\n",
       "        [180,   2],\n",
       "        [191,   2]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(encoding == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nonzero(encoding == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_aux = m.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0793, -0.6300, -0.3786,  ..., -0.2133,  2.8556, -1.1283],\n",
       "        [ 0.9498, -0.0605, -1.5593,  ..., -0.4778,  0.6944, -0.0537],\n",
       "        [-0.9065,  1.2505, -0.1733,  ..., -1.1476, -1.1839,  0.6398],\n",
       "        ...,\n",
       "        [ 1.5321, -0.4942, -0.8504,  ..., -1.7777,  0.4258,  0.4261],\n",
       "        [ 0.8070,  0.0048, -0.0686,  ..., -0.1955,  1.2301,  0.4021],\n",
       "        [-0.1257, -2.2173,  1.3299,  ...,  0.8645, -0.8442,  0.8819]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 100])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_aux.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = torch.nonzero(encoding == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 43,   1],\n",
       "        [ 56,   3],\n",
       "        [ 79,   0],\n",
       "        [ 79,   3],\n",
       "        [ 82,   1],\n",
       "        [ 96,   3],\n",
       "        [137,   0],\n",
       "        [152,   0],\n",
       "        [176,   1],\n",
       "        [187,   1]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(1):\n",
    "    \n",
    "    exclude = torch.nonzero(encoding == j)\n",
    "    \n",
    "    for k in range(exclude.shape[0]):\n",
    "        \n",
    "        exc = exclude[k]\n",
    "        \n",
    "        \n",
    "        z = m_aux[exc[0]].scatter_(0, exc[1:], 1000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000e+03,  1.0000e+03,  1.0000e+03,  1.0000e+03,  3.4074e-01,\n",
       "        -2.6404e-01, -9.2077e-01, -1.4677e-02,  1.0955e+00, -5.1544e-01,\n",
       "        -8.7062e-01,  7.6919e-01,  2.8699e-01,  9.6886e-01,  1.7844e-02,\n",
       "        -6.2256e-01, -1.1709e+00,  7.6046e-01,  5.5965e-01, -1.1070e-01,\n",
       "         6.0074e-01, -4.8264e-01, -1.9182e-01, -3.7910e-01, -5.9526e-01,\n",
       "        -9.5433e-02, -3.3138e-01,  6.0327e-01, -1.1608e+00, -7.3140e-01,\n",
       "         1.6031e-02,  9.5363e-01,  1.4151e+00,  8.6919e-01,  1.0650e+00,\n",
       "         3.5212e-01,  8.8221e-01,  8.4107e-01,  1.1909e+00, -2.7354e-01,\n",
       "         7.8464e-01,  6.9084e-01,  1.0274e-01, -3.2291e-01, -8.9670e-01,\n",
       "         3.9512e-01,  2.0630e-02,  7.4143e-01, -1.1805e+00, -1.9506e+00,\n",
       "         9.7839e-01,  1.3199e+00, -2.1029e-01,  9.7971e-01, -3.9878e-02,\n",
       "         9.6507e-01,  2.9632e-01, -1.2175e+00,  1.4639e+00,  2.0341e-01,\n",
       "        -1.4287e+00, -1.2803e-01, -1.4928e+00,  2.0406e+00,  2.4494e-01,\n",
       "        -7.2996e-01,  3.7852e-01,  1.3450e+00,  6.3191e-01, -1.8949e+00,\n",
       "         1.5382e-01,  5.0241e-01, -2.5945e+00, -2.7900e-01,  5.8742e-01,\n",
       "         1.2277e+00, -1.0679e+00,  1.4169e+00, -6.5533e-01,  4.4030e-01,\n",
       "        -1.0424e-02,  3.2266e-02,  8.6668e-01, -8.2082e-03,  5.8389e-01,\n",
       "        -9.7394e-02, -1.7314e+00, -9.3747e-01,  9.0924e-02,  8.5521e-01,\n",
       "        -1.4371e+00,  7.1737e-01, -7.2971e-01,  1.2234e+00, -2.2961e-01,\n",
       "        -1.1906e+00,  6.5359e-01, -9.0501e-01, -9.7320e-01, -8.4363e-01])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([96,  3])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(43)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 100])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_aux.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-eb70e710b179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm_aux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "m_aux[[[exclude[0]]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 100])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_aux.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0302, -0.1636, -1.7418, -0.1757,  0.3791, -0.8397, -0.7856,  1.5271,\n",
       "         -0.4584,  0.1491,  1.0438,  0.4929,  0.1003,  1.3059,  0.4218,  1.0057,\n",
       "         -1.2351, -0.1522,  0.9724,  0.4100,  0.3694,  0.3277, -0.5289, -0.4909,\n",
       "          0.3446, -1.8066,  1.0155,  0.8825, -0.2777, -1.1976,  0.2885,  0.2092,\n",
       "         -0.8086, -0.3490, -0.1686,  0.1132, -0.7963,  0.5539, -0.6405,  0.7526,\n",
       "         -1.3016, -0.1355,  0.1975, -1.7613, -0.6621, -1.1961, -0.0089,  0.2253,\n",
       "          0.0095, -0.6792, -1.4876, -0.4274,  0.0210,  0.0621, -1.9757, -0.9194,\n",
       "         -0.9840,  0.9646, -0.4086,  0.4658,  1.1966,  0.6169,  0.8855, -0.6732,\n",
       "          0.3679,  2.0794,  0.0585, -0.2454, -0.5907,  0.7409, -1.5762, -1.0074,\n",
       "          0.0781,  0.7580,  0.6308,  0.2033, -0.8695, -0.3131, -0.1380,  1.5031,\n",
       "         -0.4139,  0.3099,  0.8547, -2.8883, -0.2570,  0.2521, -0.8031, -0.0739,\n",
       "         -1.1229, -0.3560,  0.5832,  2.4520, -1.0634,  1.5417,  0.0282,  1.9118,\n",
       "          1.1215,  0.4459,  0.1537, -1.1986],\n",
       "        [ 0.9498, -0.0605, -1.5593, -1.5250, -0.6973,  0.9435,  2.4596,  1.8244,\n",
       "          0.6480, -0.2733,  0.2135,  0.2724,  1.1487,  0.5381,  0.1050,  1.0355,\n",
       "          0.7158, -0.2577,  0.5415, -1.0265, -1.1836, -0.9229,  0.7713, -0.1213,\n",
       "          1.1106,  0.5248,  1.9535,  0.0687, -1.0284,  1.7226, -1.2146,  1.0501,\n",
       "          0.0757, -2.6804,  0.7463,  1.2678, -0.4077, -1.1295, -0.2812, -1.4371,\n",
       "         -1.7414, -0.6914,  0.5389,  0.3230, -0.9886, -0.1171,  0.2021,  0.1366,\n",
       "          0.8864, -0.5756, -0.5199,  0.6171,  1.2452,  1.5872, -1.3331, -1.2504,\n",
       "         -0.5521, -0.1718, -0.4842,  0.3295, -1.1079, -0.1534, -1.0519, -1.1739,\n",
       "          0.3967,  0.9570,  1.2644, -0.0119,  0.5398, -0.1400, -0.8300, -0.4185,\n",
       "          0.3444, -1.1837,  0.6474,  0.9004,  1.8461,  1.2144,  0.8329, -0.7900,\n",
       "         -0.3941,  0.8877, -0.5457,  0.0192,  0.0996, -0.4145, -0.7247,  1.6522,\n",
       "          0.2526, -1.4347, -2.1896, -0.9847,  1.4629, -3.2909,  0.7058, -0.1187,\n",
       "          0.6049, -0.4778,  0.6944, -0.0537]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_aux[[43,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False,  True, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [ True, False, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False,  True, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [ True, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [ True, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False,  True, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False,  True, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-7.9326e-02, -6.2997e-01, -3.7863e-01,  2.9347e-01, -4.6815e-01,\n",
       "        -1.2414e-03, -3.9178e-02,  1.1563e+00,  1.4654e+00, -2.7126e-01,\n",
       "        -1.8753e+00,  7.5393e-01,  1.6476e-01, -1.5836e+00,  5.6198e-01,\n",
       "         2.5038e-01,  3.1218e-01,  1.0094e+00,  1.2251e+00,  1.9295e-01,\n",
       "        -1.5820e-01,  8.2826e-01, -1.5143e+00,  3.7592e-01, -1.2277e-01,\n",
       "        -1.4465e+00, -1.3537e+00,  7.7615e-01, -5.9863e-01,  2.5851e-03,\n",
       "        -6.4988e-01, -5.5231e-01,  1.6726e-02,  5.1850e-01,  8.4310e-01,\n",
       "        -9.1750e-01,  1.5605e-01, -8.0841e-01, -1.0547e+00,  6.9209e-01,\n",
       "         3.0936e-01,  5.4713e-01, -9.7568e-01, -1.7187e+00, -1.5435e+00,\n",
       "         4.0454e-02, -7.6023e-01, -2.3817e-01,  1.1795e+00,  1.0296e+00,\n",
       "         2.0394e-01,  1.1942e+00,  8.0457e-01,  3.0606e-01, -6.8432e-01,\n",
       "        -4.9388e-03, -8.1257e-01, -1.9065e-01,  6.7450e-02,  7.8054e-01,\n",
       "         1.5632e-01,  6.7083e-01, -1.8288e+00, -1.3203e+00, -2.0107e+00,\n",
       "         5.3763e-01, -4.7031e-01,  1.3088e+00, -7.3765e-02, -7.3893e-01,\n",
       "         1.4691e+00,  9.8000e-01, -1.2233e+00,  1.0147e+00, -6.8889e-01,\n",
       "        -1.6398e-01,  6.7083e-02,  2.4627e-01, -9.6570e-01, -9.3843e-02,\n",
       "         3.5888e-01,  1.4798e+00,  1.2597e-01,  1.5530e+00, -1.7768e+00,\n",
       "         8.8908e-01, -2.0531e-01,  1.3131e+00,  3.3952e-01,  1.0374e+00,\n",
       "         1.8416e-01,  3.7972e+00, -3.4437e-01,  1.2769e+00,  5.5517e-01,\n",
       "        -8.9504e-02, -1.0492e-01, -2.1333e-01,  2.8556e+00, -1.1283e+00])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[0, k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 4])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.take(m[0], encoding).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.1850e-01, -2.7126e-01,  1.6726e-02, -2.3817e-01],\n",
       "        [-9.3843e-02,  3.5888e-01,  1.1795e+00, -1.0492e-01],\n",
       "        [ 5.1850e-01, -9.7568e-01,  8.0457e-01,  6.9209e-01],\n",
       "        [-7.6023e-01,  9.8000e-01, -1.4465e+00,  1.1942e+00],\n",
       "        [-1.8753e+00,  3.7592e-01, -1.2233e+00, -7.6023e-01],\n",
       "        [ 3.0936e-01,  1.1795e+00, -1.3537e+00,  5.5517e-01],\n",
       "        [-8.1257e-01,  5.3763e-01, -1.6398e-01,  7.5393e-01],\n",
       "        [-1.7768e+00, -1.3537e+00,  1.2597e-01,  3.7592e-01],\n",
       "        [-3.9178e-02,  2.9347e-01, -1.8288e+00,  1.0094e+00],\n",
       "        [ 1.2251e+00,  1.0296e+00,  1.1563e+00,  1.6726e-02],\n",
       "        [ 3.0936e-01,  1.1563e+00,  7.7615e-01, -1.7768e+00],\n",
       "        [-9.7568e-01, -1.3203e+00,  1.6476e-01,  1.5530e+00],\n",
       "        [ 1.3088e+00,  5.5517e-01, -1.2414e-03,  2.5038e-01],\n",
       "        [-5.5231e-01,  1.0374e+00, -1.2233e+00, -1.2233e+00],\n",
       "        [-1.6398e-01, -8.0841e-01, -9.3843e-02,  1.2597e-01],\n",
       "        [-7.3765e-02, -2.7126e-01,  1.4654e+00, -2.0531e-01],\n",
       "        [-1.2233e+00, -2.0531e-01,  3.0936e-01, -1.7768e+00],\n",
       "        [-8.9504e-02,  1.5632e-01, -6.4988e-01,  5.6198e-01],\n",
       "        [-1.5143e+00, -9.7568e-01, -2.7126e-01,  2.5038e-01],\n",
       "        [ 1.1942e+00,  8.8908e-01, -1.5820e-01,  6.7083e-02],\n",
       "        [-3.4437e-01,  5.6198e-01,  1.6476e-01, -9.6570e-01],\n",
       "        [ 3.1218e-01,  3.5888e-01,  2.0394e-01,  5.4713e-01],\n",
       "        [ 1.9295e-01, -9.7568e-01,  2.4627e-01,  3.5888e-01],\n",
       "        [-1.8288e+00, -4.6815e-01,  2.4627e-01, -9.7568e-01],\n",
       "        [ 8.4310e-01,  2.4627e-01,  5.5517e-01,  3.3952e-01],\n",
       "        [ 1.3088e+00,  8.8908e-01, -1.8288e+00,  4.0454e-02],\n",
       "        [-8.0841e-01, -2.0531e-01,  3.3952e-01,  6.9209e-01],\n",
       "        [-6.8432e-01, -2.3817e-01, -1.5836e+00,  1.3088e+00],\n",
       "        [-1.0547e+00,  1.0374e+00,  1.0094e+00,  2.0394e-01],\n",
       "        [-2.0531e-01, -2.3817e-01, -1.0492e-01,  3.7592e-01],\n",
       "        [-2.0107e+00,  1.2769e+00, -7.6023e-01, -4.6815e-01],\n",
       "        [ 1.3088e+00, -1.2414e-03,  1.4654e+00,  3.5888e-01],\n",
       "        [-1.2414e-03,  5.6198e-01, -6.8889e-01, -2.0107e+00],\n",
       "        [ 1.8416e-01, -7.3765e-02,  1.9295e-01,  5.3763e-01],\n",
       "        [-1.5143e+00,  2.9347e-01, -7.3765e-02,  1.0374e+00],\n",
       "        [ 6.9209e-01, -7.3765e-02, -1.7187e+00, -8.0841e-01],\n",
       "        [-4.9388e-03,  8.2826e-01,  1.3088e+00, -1.5836e+00],\n",
       "        [-7.3893e-01, -7.6023e-01,  1.1942e+00,  3.7972e+00],\n",
       "        [-1.5820e-01,  3.7592e-01,  7.8054e-01, -8.9504e-02],\n",
       "        [ 7.5393e-01, -3.4437e-01,  8.0457e-01,  7.5393e-01],\n",
       "        [ 4.0454e-02,  1.5530e+00, -4.9388e-03, -6.8889e-01],\n",
       "        [-2.0531e-01, -8.0841e-01,  1.8416e-01,  1.5632e-01],\n",
       "        [-4.9388e-03,  9.8000e-01,  3.7592e-01, -1.8753e+00],\n",
       "        [ 1.9295e-01, -7.9326e-02,  3.0936e-01, -1.3537e+00],\n",
       "        [-1.2414e-03, -1.5820e-01, -1.5435e+00,  3.7592e-01],\n",
       "        [-1.0492e-01, -6.4988e-01,  5.6198e-01,  8.2826e-01],\n",
       "        [-6.8889e-01, -1.1283e+00,  2.0394e-01, -1.5143e+00],\n",
       "        [ 1.0094e+00,  1.0374e+00,  5.6198e-01,  5.1850e-01],\n",
       "        [ 3.3952e-01, -6.2997e-01,  2.5038e-01,  1.0094e+00],\n",
       "        [ 5.4713e-01,  1.1563e+00,  6.7083e-02, -6.2997e-01],\n",
       "        [ 5.5517e-01,  5.5517e-01,  8.8908e-01,  2.0394e-01],\n",
       "        [-8.0841e-01,  9.8000e-01, -9.7568e-01,  5.4713e-01],\n",
       "        [ 1.5632e-01, -6.8889e-01, -1.3203e+00, -2.0107e+00],\n",
       "        [ 3.0936e-01, -6.8432e-01, -1.2414e-03,  3.5888e-01],\n",
       "        [-2.7126e-01, -1.8753e+00, -7.3765e-02,  1.5530e+00],\n",
       "        [-1.5820e-01,  1.2769e+00, -8.9504e-02,  1.2769e+00],\n",
       "        [-1.5435e+00,  5.1850e-01,  3.3952e-01, -7.9326e-02],\n",
       "        [-2.7126e-01,  1.4654e+00,  8.0457e-01, -1.9065e-01],\n",
       "        [-1.3537e+00, -2.0107e+00,  4.0454e-02, -8.9504e-02],\n",
       "        [ 2.4627e-01,  6.7083e-02, -4.9388e-03,  7.5393e-01],\n",
       "        [-6.2997e-01,  6.7083e-01,  1.0147e+00,  1.5530e+00],\n",
       "        [ 1.2251e+00,  1.1942e+00,  8.0457e-01, -1.1283e+00],\n",
       "        [-1.2277e-01,  1.8416e-01, -2.3817e-01,  1.5605e-01],\n",
       "        [-1.7768e+00, -1.2414e-03, -2.0107e+00, -9.1750e-01],\n",
       "        [-6.8432e-01,  9.8000e-01,  1.3088e+00, -5.5231e-01],\n",
       "        [ 1.6476e-01,  6.7450e-02,  1.6476e-01,  8.2826e-01],\n",
       "        [-4.7031e-01,  1.5530e+00, -5.9863e-01,  1.6726e-02],\n",
       "        [-6.8889e-01,  1.4691e+00, -7.3765e-02,  1.2251e+00],\n",
       "        [-8.0841e-01,  5.4713e-01, -1.7768e+00, -6.4988e-01],\n",
       "        [ 1.1795e+00,  8.0457e-01,  4.0454e-02,  7.5393e-01],\n",
       "        [-9.6570e-01,  2.8556e+00, -1.2233e+00,  1.1563e+00],\n",
       "        [ 8.2826e-01,  1.1942e+00,  6.7083e-01,  1.6476e-01],\n",
       "        [ 3.7592e-01, -6.8432e-01,  1.5632e-01,  9.8000e-01],\n",
       "        [-2.3817e-01, -1.2414e-03,  6.7083e-02, -3.4437e-01],\n",
       "        [ 2.5038e-01, -6.8432e-01,  1.2251e+00, -7.3765e-02],\n",
       "        [ 1.4798e+00,  1.8416e-01,  3.0936e-01, -1.0547e+00],\n",
       "        [ 7.5393e-01,  2.5851e-03, -2.0531e-01, -1.3537e+00],\n",
       "        [ 9.8000e-01,  3.7972e+00, -7.3765e-02,  9.8000e-01],\n",
       "        [-1.2233e+00, -1.5820e-01,  1.4654e+00, -3.4437e-01],\n",
       "        [-7.9326e-02,  7.5393e-01, -1.5836e+00, -7.9326e-02],\n",
       "        [-7.3893e-01, -9.3843e-02,  6.7450e-02, -3.9178e-02],\n",
       "        [ 1.5632e-01, -9.6570e-01, -2.0531e-01,  1.9295e-01],\n",
       "        [-1.3203e+00, -7.9326e-02, -1.7768e+00, -2.3817e-01],\n",
       "        [ 1.0094e+00, -7.6023e-01, -3.9178e-02, -9.1750e-01],\n",
       "        [ 5.5517e-01,  7.5393e-01, -8.9504e-02, -3.7863e-01],\n",
       "        [-2.0107e+00, -2.1333e-01, -9.6570e-01, -1.1283e+00],\n",
       "        [ 3.7972e+00, -1.2233e+00,  2.0394e-01, -8.9504e-02],\n",
       "        [-4.7031e-01,  1.0094e+00, -1.8753e+00,  3.5888e-01],\n",
       "        [-1.5435e+00, -9.1750e-01, -2.3817e-01,  2.5851e-03],\n",
       "        [ 1.4654e+00,  8.0457e-01,  5.4713e-01,  1.4654e+00],\n",
       "        [-8.9504e-02, -1.1283e+00,  8.0457e-01,  5.5517e-01],\n",
       "        [-9.6570e-01,  8.4310e-01, -2.3817e-01, -9.6570e-01],\n",
       "        [ 2.5038e-01, -2.0107e+00,  1.4691e+00,  3.3952e-01],\n",
       "        [ 3.7972e+00,  7.5393e-01, -1.7187e+00, -1.5143e+00],\n",
       "        [ 8.4310e-01, -1.3203e+00, -6.8432e-01, -3.9178e-02],\n",
       "        [ 6.7450e-02,  3.0936e-01,  1.4654e+00,  3.0606e-01],\n",
       "        [ 3.7972e+00,  6.7083e-02, -9.1750e-01, -7.9326e-02],\n",
       "        [ 9.8000e-01, -4.9388e-03,  1.9295e-01, -6.8889e-01],\n",
       "        [-4.9388e-03,  1.4654e+00,  5.6198e-01,  1.5530e+00],\n",
       "        [-8.9504e-02,  3.7592e-01, -1.2277e-01,  5.1850e-01],\n",
       "        [-1.3203e+00,  1.2769e+00,  1.1795e+00,  2.5851e-03],\n",
       "        [ 7.5393e-01,  1.0094e+00, -5.9863e-01,  3.3952e-01],\n",
       "        [ 1.2597e-01, -2.3817e-01, -2.1333e-01,  2.8556e+00],\n",
       "        [ 7.7615e-01, -8.9504e-02,  3.1218e-01,  2.5851e-03],\n",
       "        [ 1.3131e+00, -4.7031e-01,  1.3088e+00, -1.5820e-01],\n",
       "        [-1.9065e-01, -1.7187e+00, -4.7031e-01,  2.9347e-01],\n",
       "        [ 8.2826e-01,  1.0374e+00,  5.3763e-01, -1.5836e+00],\n",
       "        [-1.2233e+00, -2.0107e+00,  1.5632e-01,  5.5517e-01],\n",
       "        [-1.5836e+00,  1.6476e-01,  8.4310e-01,  2.5038e-01],\n",
       "        [-7.6023e-01, -1.2277e-01, -9.1750e-01,  2.4627e-01],\n",
       "        [-1.2233e+00, -1.0547e+00,  8.0457e-01, -1.5836e+00],\n",
       "        [-1.1283e+00,  6.7083e-02,  7.5393e-01,  4.0454e-02],\n",
       "        [-1.0492e-01,  1.4691e+00, -3.9178e-02,  2.5038e-01],\n",
       "        [ 8.0457e-01,  1.8416e-01,  5.6198e-01,  1.4654e+00],\n",
       "        [-3.7863e-01, -1.5820e-01,  6.9209e-01,  1.6726e-02],\n",
       "        [-2.3817e-01, -6.8432e-01, -3.9178e-02,  1.8416e-01],\n",
       "        [-6.8889e-01, -2.3817e-01,  1.3088e+00,  1.0296e+00],\n",
       "        [-1.0547e+00,  2.8556e+00, -1.5143e+00,  1.4654e+00],\n",
       "        [-1.0547e+00, -6.8889e-01, -4.7031e-01, -6.4988e-01],\n",
       "        [ 1.1942e+00,  5.4713e-01,  7.5393e-01,  1.4798e+00],\n",
       "        [ 1.3131e+00, -1.6398e-01,  1.5530e+00, -6.8889e-01],\n",
       "        [-1.6398e-01, -9.6570e-01,  1.5530e+00, -8.0841e-01],\n",
       "        [-2.3817e-01, -6.8432e-01, -3.9178e-02, -7.3893e-01],\n",
       "        [ 3.0936e-01,  1.5605e-01, -1.4465e+00, -1.9065e-01],\n",
       "        [ 1.3131e+00, -6.4988e-01,  3.7592e-01, -2.7126e-01],\n",
       "        [-3.9178e-02,  6.7083e-01,  1.9295e-01,  1.1563e+00],\n",
       "        [-8.9504e-02,  5.5517e-01,  3.7592e-01, -6.8889e-01],\n",
       "        [ 1.2597e-01, -1.6398e-01, -4.7031e-01,  6.7083e-02],\n",
       "        [-1.2277e-01,  1.1795e+00,  5.6198e-01, -1.6398e-01],\n",
       "        [ 6.7450e-02, -8.1257e-01,  3.0936e-01, -1.2414e-03],\n",
       "        [ 1.0094e+00, -6.8432e-01,  3.7972e+00,  1.4798e+00],\n",
       "        [-1.5435e+00, -1.9065e-01,  5.4713e-01, -6.4988e-01],\n",
       "        [ 6.7083e-01,  7.8054e-01, -2.3817e-01, -3.4437e-01],\n",
       "        [-1.8753e+00,  7.5393e-01, -1.5836e+00,  1.3088e+00],\n",
       "        [ 5.4713e-01, -1.5435e+00, -3.7863e-01, -1.3537e+00],\n",
       "        [-1.0492e-01,  2.5038e-01,  1.4691e+00,  2.5038e-01],\n",
       "        [ 5.3763e-01, -1.4465e+00,  5.5517e-01,  1.6726e-02],\n",
       "        [-7.9326e-02, -1.5836e+00,  6.7083e-01, -1.3203e+00],\n",
       "        [-9.6570e-01, -9.7568e-01,  6.7083e-02, -1.3537e+00],\n",
       "        [ 5.4713e-01,  1.6726e-02,  1.2597e-01,  7.7615e-01],\n",
       "        [ 6.7083e-02, -1.7187e+00, -9.6570e-01,  1.4798e+00],\n",
       "        [ 2.5851e-03, -3.4437e-01,  1.0094e+00, -4.9388e-03],\n",
       "        [-6.8889e-01,  6.7083e-01,  7.5393e-01,  5.4713e-01],\n",
       "        [-2.7126e-01, -1.8288e+00, -5.9863e-01,  8.8908e-01],\n",
       "        [ 3.7592e-01, -1.2277e-01,  1.5605e-01,  5.5517e-01],\n",
       "        [ 9.8000e-01,  5.5517e-01, -4.7031e-01, -1.2233e+00],\n",
       "        [ 1.9295e-01, -2.0531e-01, -1.5435e+00,  1.0296e+00],\n",
       "        [ 5.1850e-01, -8.0841e-01, -1.5143e+00, -1.0547e+00],\n",
       "        [ 3.0936e-01, -6.8889e-01,  1.9295e-01, -3.7863e-01],\n",
       "        [ 1.4654e+00, -1.3203e+00,  1.9295e-01, -9.3843e-02],\n",
       "        [-1.8753e+00,  1.3088e+00,  2.0394e-01,  1.2597e-01],\n",
       "        [ 8.8908e-01, -1.5435e+00,  7.7615e-01,  8.0457e-01],\n",
       "        [-7.9326e-02, -1.0547e+00,  1.3131e+00,  1.9295e-01],\n",
       "        [ 1.2251e+00, -1.8288e+00,  1.4798e+00, -8.9504e-02],\n",
       "        [ 8.0457e-01, -3.4437e-01,  1.2597e-01,  5.1850e-01],\n",
       "        [ 3.0936e-01,  1.1942e+00, -1.8753e+00, -4.6815e-01],\n",
       "        [ 5.5517e-01,  1.2597e-01,  2.4627e-01, -2.0531e-01],\n",
       "        [-1.5820e-01, -1.7187e+00,  2.5038e-01, -3.9178e-02],\n",
       "        [-7.3765e-02, -1.3203e+00,  8.8908e-01,  6.7450e-02],\n",
       "        [-1.5836e+00,  1.0147e+00, -5.9863e-01,  5.6198e-01],\n",
       "        [-8.0841e-01, -1.8288e+00, -1.5143e+00,  5.5517e-01],\n",
       "        [-1.3203e+00,  1.5632e-01, -1.1283e+00, -5.9863e-01],\n",
       "        [ 1.2251e+00, -2.0107e+00,  8.8908e-01,  2.8556e+00],\n",
       "        [ 8.0457e-01,  2.9347e-01, -8.9504e-02,  6.7083e-01],\n",
       "        [-1.8288e+00,  1.5632e-01, -1.5820e-01,  6.9209e-01],\n",
       "        [-6.4988e-01,  1.0374e+00, -5.5231e-01,  3.7972e+00],\n",
       "        [-5.5231e-01,  1.4691e+00, -9.1750e-01,  1.0147e+00],\n",
       "        [ 4.0454e-02, -6.8432e-01,  1.0374e+00,  8.8908e-01],\n",
       "        [ 2.5851e-03, -8.1257e-01, -9.6570e-01,  5.5517e-01],\n",
       "        [-6.8432e-01,  8.0457e-01,  8.8908e-01,  7.5393e-01],\n",
       "        [ 2.9347e-01,  3.1218e-01, -1.5820e-01,  5.1850e-01],\n",
       "        [ 1.2769e+00, -4.9388e-03, -6.8432e-01,  1.2251e+00],\n",
       "        [-3.4437e-01, -2.0531e-01,  3.0936e-01,  5.5517e-01],\n",
       "        [ 3.3952e-01,  1.1795e+00,  8.0457e-01,  6.7083e-02],\n",
       "        [ 1.5632e-01,  3.0936e-01, -4.7031e-01, -6.2997e-01],\n",
       "        [ 3.7972e+00,  5.3763e-01, -8.9504e-02, -2.7126e-01],\n",
       "        [ 2.5851e-03, -7.9326e-02, -8.0841e-01, -3.4437e-01],\n",
       "        [ 1.8416e-01, -3.7863e-01,  2.9347e-01, -1.4465e+00],\n",
       "        [-6.8889e-01, -8.9504e-02,  5.1850e-01,  1.0296e+00],\n",
       "        [-1.8288e+00,  5.4713e-01,  2.0394e-01, -9.3843e-02],\n",
       "        [-1.7768e+00, -8.1257e-01,  1.2251e+00, -1.5143e+00],\n",
       "        [ 3.1218e-01,  1.1795e+00,  5.5517e-01, -4.7031e-01],\n",
       "        [ 3.0936e-01, -2.3817e-01, -3.4437e-01,  1.6476e-01],\n",
       "        [-1.7768e+00, -8.1257e-01, -3.4437e-01,  1.9295e-01],\n",
       "        [-1.2277e-01, -1.5836e+00, -9.6570e-01, -8.1257e-01],\n",
       "        [ 1.6726e-02, -4.6815e-01, -7.3893e-01, -5.5231e-01],\n",
       "        [-7.3765e-02,  1.9295e-01,  1.0094e+00,  1.0374e+00],\n",
       "        [ 1.0094e+00, -7.9326e-02, -5.9863e-01,  2.5038e-01],\n",
       "        [ 1.0374e+00,  8.0457e-01,  1.2769e+00,  1.1563e+00],\n",
       "        [ 3.0936e-01,  1.0147e+00, -9.3843e-02, -8.9504e-02],\n",
       "        [-1.6398e-01,  2.5038e-01, -6.8889e-01, -9.7568e-01],\n",
       "        [ 1.8416e-01,  6.9209e-01, -2.1333e-01, -9.3843e-02],\n",
       "        [ 6.7083e-02,  3.1218e-01, -1.5836e+00,  1.0147e+00],\n",
       "        [-3.4437e-01,  1.2251e+00,  2.9347e-01,  3.7972e+00],\n",
       "        [ 2.5851e-03, -1.4465e+00,  3.5888e-01,  1.4798e+00],\n",
       "        [-4.9388e-03,  2.4627e-01,  1.4654e+00,  3.7972e+00],\n",
       "        [-1.5820e-01, -1.9065e-01, -2.1333e-01, -6.4988e-01],\n",
       "        [ 1.5632e-01,  1.0374e+00, -2.0107e+00,  8.0457e-01],\n",
       "        [ 8.0457e-01, -3.7863e-01, -1.2414e-03,  1.3131e+00],\n",
       "        [ 8.0457e-01,  1.0147e+00,  7.8054e-01,  1.9295e-01]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.take(m[0], encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[33,  9, 32, 47],\n",
       "        [79, 80, 48, 96],\n",
       "        [33, 42, 52, 39],\n",
       "        [46, 71, 25, 51],\n",
       "        [10, 23, 72, 46],\n",
       "        [40, 48, 26, 94],\n",
       "        [56, 65, 75, 11],\n",
       "        [84, 26, 82, 23],\n",
       "        [ 6,  3, 62, 17],\n",
       "        [18, 49,  7, 32],\n",
       "        [40,  7, 27, 84],\n",
       "        [42, 63, 12, 83],\n",
       "        [67, 94,  5, 15],\n",
       "        [31, 89, 72, 72],\n",
       "        [75, 37, 79, 82],\n",
       "        [68,  9,  8, 86],\n",
       "        [72, 86, 40, 84],\n",
       "        [95, 60, 30, 14],\n",
       "        [22, 42,  9, 15],\n",
       "        [51, 85, 20, 76],\n",
       "        [92, 14, 12, 78],\n",
       "        [16, 80, 50, 41],\n",
       "        [19, 42, 77, 80],\n",
       "        [62,  4, 77, 42],\n",
       "        [34, 77, 94, 88],\n",
       "        [67, 85, 62, 45],\n",
       "        [37, 86, 88, 39],\n",
       "        [54, 47, 13, 67],\n",
       "        [38, 89, 17, 50],\n",
       "        [86, 47, 96, 23],\n",
       "        [64, 93, 46,  4],\n",
       "        [67,  5,  8, 80],\n",
       "        [ 5, 14, 74, 64],\n",
       "        [90, 68, 19, 65],\n",
       "        [22,  3, 68, 89],\n",
       "        [39, 68, 43, 37],\n",
       "        [55, 21, 67, 13],\n",
       "        [69, 46, 51, 91],\n",
       "        [20, 23, 59, 95],\n",
       "        [11, 92, 52, 11],\n",
       "        [45, 83, 55, 74],\n",
       "        [86, 37, 90, 60],\n",
       "        [55, 71, 23, 10],\n",
       "        [19,  0, 40, 26],\n",
       "        [ 5, 20, 44, 23],\n",
       "        [96, 30, 14, 21],\n",
       "        [74, 99, 50, 22],\n",
       "        [17, 89, 14, 33],\n",
       "        [88,  1, 15, 17],\n",
       "        [41,  7, 76,  1],\n",
       "        [94, 94, 85, 50],\n",
       "        [37, 71, 42, 41],\n",
       "        [60, 74, 63, 64],\n",
       "        [40, 54,  5, 80],\n",
       "        [ 9, 10, 68, 83],\n",
       "        [20, 93, 95, 93],\n",
       "        [44, 33, 88,  0],\n",
       "        [ 9,  8, 52, 57],\n",
       "        [26, 64, 45, 95],\n",
       "        [77, 76, 55, 11],\n",
       "        [ 1, 61, 73, 83],\n",
       "        [18, 51, 52, 99],\n",
       "        [24, 90, 47, 36],\n",
       "        [84,  5, 64, 35],\n",
       "        [54, 71, 67, 31],\n",
       "        [12, 58, 12, 21],\n",
       "        [66, 83, 28, 32],\n",
       "        [74, 70, 68, 18],\n",
       "        [37, 41, 84, 30],\n",
       "        [48, 52, 45, 11],\n",
       "        [78, 98, 72,  7],\n",
       "        [21, 51, 61, 12],\n",
       "        [23, 54, 60, 71],\n",
       "        [47,  5, 76, 92],\n",
       "        [15, 54, 18, 68],\n",
       "        [81, 90, 40, 38],\n",
       "        [11, 29, 86, 26],\n",
       "        [71, 91, 68, 71],\n",
       "        [72, 20,  8, 92],\n",
       "        [ 0, 11, 13,  0],\n",
       "        [69, 79, 58,  6],\n",
       "        [60, 78, 86, 19],\n",
       "        [63,  0, 84, 47],\n",
       "        [17, 46,  6, 35],\n",
       "        [94, 11, 95,  2],\n",
       "        [64, 97, 78, 99],\n",
       "        [91, 72, 50, 95],\n",
       "        [66, 17, 10, 80],\n",
       "        [44, 35, 47, 29],\n",
       "        [ 8, 52, 41,  8],\n",
       "        [95, 99, 52, 94],\n",
       "        [78, 34, 47, 78],\n",
       "        [15, 64, 70, 88],\n",
       "        [91, 11, 43, 22],\n",
       "        [34, 63, 54,  6],\n",
       "        [58, 40,  8, 53],\n",
       "        [91, 76, 35,  0],\n",
       "        [71, 55, 19, 74],\n",
       "        [55,  8, 14, 83],\n",
       "        [95, 23, 24, 33],\n",
       "        [63, 93, 48, 29],\n",
       "        [11, 17, 28, 88],\n",
       "        [82, 47, 97, 98],\n",
       "        [27, 95, 16, 29],\n",
       "        [87, 66, 67, 20],\n",
       "        [57, 43, 66,  3],\n",
       "        [21, 89, 65, 13],\n",
       "        [72, 64, 60, 94],\n",
       "        [13, 12, 34, 15],\n",
       "        [46, 24, 35, 77],\n",
       "        [72, 38, 52, 13],\n",
       "        [99, 76, 11, 45],\n",
       "        [96, 70,  6, 15],\n",
       "        [52, 90, 14,  8],\n",
       "        [ 2, 20, 39, 32],\n",
       "        [47, 54,  6, 90],\n",
       "        [74, 47, 67, 49],\n",
       "        [38, 98, 22,  8],\n",
       "        [38, 74, 66, 30],\n",
       "        [51, 41, 11, 81],\n",
       "        [87, 75, 83, 74],\n",
       "        [75, 78, 83, 37],\n",
       "        [47, 54,  6, 69],\n",
       "        [40, 36, 25, 57],\n",
       "        [87, 30, 23,  9],\n",
       "        [ 6, 61, 19,  7],\n",
       "        [95, 94, 23, 74],\n",
       "        [82, 75, 66, 76],\n",
       "        [24, 48, 14, 75],\n",
       "        [58, 56, 40,  5],\n",
       "        [17, 54, 91, 81],\n",
       "        [44, 57, 41, 30],\n",
       "        [61, 59, 47, 92],\n",
       "        [10, 11, 13, 67],\n",
       "        [41, 44,  2, 26],\n",
       "        [96, 15, 70, 15],\n",
       "        [65, 25, 94, 32],\n",
       "        [ 0, 13, 61, 63],\n",
       "        [78, 42, 76, 26],\n",
       "        [41, 32, 82, 27],\n",
       "        [76, 43, 78, 81],\n",
       "        [29, 92, 17, 55],\n",
       "        [74, 61, 11, 41],\n",
       "        [ 9, 62, 28, 85],\n",
       "        [23, 24, 36, 94],\n",
       "        [71, 94, 66, 72],\n",
       "        [19, 86, 44, 49],\n",
       "        [33, 37, 22, 38],\n",
       "        [40, 74, 19,  2],\n",
       "        [ 8, 63, 19, 79],\n",
       "        [10, 67, 50, 82],\n",
       "        [85, 44, 27, 52],\n",
       "        [ 0, 38, 87, 19],\n",
       "        [18, 62, 81, 95],\n",
       "        [52, 92, 82, 33],\n",
       "        [40, 51, 10,  4],\n",
       "        [94, 82, 77, 86],\n",
       "        [20, 43, 15,  6],\n",
       "        [68, 63, 85, 58],\n",
       "        [13, 73, 28, 14],\n",
       "        [37, 62, 22, 94],\n",
       "        [63, 60, 99, 28],\n",
       "        [18, 64, 85, 98],\n",
       "        [52,  3, 95, 61],\n",
       "        [62, 60, 20, 39],\n",
       "        [30, 89, 31, 91],\n",
       "        [31, 70, 35, 73],\n",
       "        [45, 54, 89, 85],\n",
       "        [29, 56, 78, 94],\n",
       "        [54, 52, 85, 11],\n",
       "        [ 3, 16, 20, 33],\n",
       "        [93, 55, 54, 18],\n",
       "        [92, 86, 40, 94],\n",
       "        [88, 48, 52, 76],\n",
       "        [60, 40, 66,  1],\n",
       "        [91, 65, 95,  9],\n",
       "        [29,  0, 37, 92],\n",
       "        [90,  2,  3, 25],\n",
       "        [74, 95, 33, 49],\n",
       "        [62, 41, 50, 79],\n",
       "        [84, 56, 18, 22],\n",
       "        [16, 48, 94, 66],\n",
       "        [40, 47, 92, 12],\n",
       "        [84, 56, 92, 19],\n",
       "        [24, 13, 78, 56],\n",
       "        [32,  4, 69, 31],\n",
       "        [68, 19, 17, 89],\n",
       "        [17,  0, 28, 15],\n",
       "        [89, 52, 93,  7],\n",
       "        [40, 73, 79, 95],\n",
       "        [75, 15, 74, 42],\n",
       "        [90, 39, 97, 79],\n",
       "        [76, 16, 13, 73],\n",
       "        [92, 18,  3, 91],\n",
       "        [29, 25, 80, 81],\n",
       "        [55, 77,  8, 91],\n",
       "        [20, 57, 97, 30],\n",
       "        [60, 89, 64, 52],\n",
       "        [52,  2,  5, 87],\n",
       "        [52, 73, 59, 19]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4000, -0.4000,  0.4000,  0.4000,  0.4000,  0.4000, -0.4000, -0.4000,\n",
       "         0.4000, -0.4000,  0.4000,  0.4000, -0.4000, -0.4000,  0.4000, -0.4000,\n",
       "         0.4000, -0.4000, -0.4000, -0.4000,  0.4000,  0.4000,  0.4000,  0.4000,\n",
       "        -0.4000,  0.4000,  0.4000,  0.4000,  0.4000,  0.4000,  0.4000, -0.4000,\n",
       "         0.4000, -0.4000, -0.4000, -0.4000,  0.4000,  0.4000,  0.4000,  0.4000,\n",
       "        -0.4000,  0.4000,  0.4000, -0.4000,  0.4000, -0.4000,  0.4000, -0.4000,\n",
       "        -0.4000,  0.4000,  0.4000, -0.4000, -0.4000, -0.4000,  0.4000,  0.4000,\n",
       "         0.4000, -0.4000, -0.4000,  0.4000,  0.4000,  0.4000,  0.4000, -0.4000,\n",
       "        -0.4000,  0.4000,  0.4000, -0.4000,  0.4000,  0.4000, -0.4000,  0.4000,\n",
       "        -0.4000,  0.4000,  0.4000,  0.4000, -0.4000, -0.4000,  0.4000, -0.4000,\n",
       "         0.4000, -0.4000,  0.4000,  0.4000,  0.4000,  0.4000,  0.4000, -0.4000,\n",
       "         0.4000,  0.4000,  0.4000,  0.4000, -0.4000,  0.4000,  0.4000, -0.4000,\n",
       "         0.4000, -0.4000,  0.4000, -0.4000, -0.4000,  0.4000, -0.4000,  0.4000,\n",
       "         0.4000,  0.4000,  0.4000,  0.4000, -0.4000,  0.4000,  0.4000, -0.4000,\n",
       "         0.4000,  0.4000,  0.4000,  0.4000,  0.4000, -0.4000,  0.4000,  0.4000,\n",
       "        -0.4000, -0.4000,  0.4000,  0.4000,  0.4000,  0.4000,  0.4000,  0.4000,\n",
       "         0.4000,  0.4000, -0.4000,  0.4000, -0.4000,  0.4000, -0.4000, -0.4000,\n",
       "         0.4000, -0.4000,  0.4000,  0.4000, -0.4000,  0.4000,  0.4000,  0.4000,\n",
       "         0.4000, -0.4000,  0.4000,  0.4000,  0.4000, -0.4000, -0.4000, -0.4000,\n",
       "        -0.4000,  0.4000, -0.4000,  0.4000,  0.4000, -0.4000, -0.4000,  0.4000,\n",
       "        -0.4000,  0.4000, -0.4000,  0.4000, -0.4000,  0.4000,  0.4000,  0.4000,\n",
       "        -0.4000, -0.4000,  0.4000,  0.4000,  0.4000,  0.4000,  0.4000,  0.4000,\n",
       "        -0.4000,  0.4000, -0.4000,  0.4000, -0.4000,  0.4000,  0.4000, -0.4000,\n",
       "         0.4000,  0.4000, -0.4000, -0.4000, -0.4000,  0.4000,  0.4000,  0.4000,\n",
       "         0.4000,  0.4000,  0.4000,  0.4000,  0.4000, -0.4000, -0.4000, -0.4000])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tanh(beta*J_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-7.9326e-02, -6.2997e-01, -3.7863e-01,  2.9347e-01, -4.6815e-01,\n",
       "        -1.2414e-03, -3.9178e-02,  1.1563e+00,  1.4654e+00, -2.7126e-01,\n",
       "        -1.8753e+00,  7.5393e-01,  1.6476e-01, -1.5836e+00,  5.6198e-01,\n",
       "         2.5038e-01,  3.1218e-01,  1.0094e+00,  1.2251e+00,  1.9295e-01,\n",
       "        -1.5820e-01,  8.2826e-01, -1.5143e+00,  3.7592e-01, -1.2277e-01,\n",
       "        -1.4465e+00, -1.3537e+00,  7.7615e-01, -5.9863e-01,  2.5851e-03,\n",
       "        -6.4988e-01, -5.5231e-01,  1.6726e-02,  5.1850e-01,  8.4310e-01,\n",
       "        -9.1750e-01,  1.5605e-01, -8.0841e-01, -1.0547e+00,  6.9209e-01,\n",
       "         3.0936e-01,  5.4713e-01, -9.7568e-01, -1.7187e+00, -1.5435e+00,\n",
       "         4.0454e-02, -7.6023e-01, -2.3817e-01,  1.1795e+00,  1.0296e+00,\n",
       "         2.0394e-01,  1.1942e+00,  8.0457e-01,  3.0606e-01, -6.8432e-01,\n",
       "        -4.9388e-03, -8.1257e-01, -1.9065e-01,  6.7450e-02,  7.8054e-01,\n",
       "         1.5632e-01,  6.7083e-01, -1.8288e+00, -1.3203e+00, -2.0107e+00,\n",
       "         5.3763e-01, -4.7031e-01,  1.3088e+00, -7.3765e-02, -7.3893e-01,\n",
       "         1.4691e+00,  9.8000e-01, -1.2233e+00,  1.0147e+00, -6.8889e-01,\n",
       "        -1.6398e-01,  6.7083e-02,  2.4627e-01, -9.6570e-01, -9.3843e-02,\n",
       "         3.5888e-01,  1.4798e+00,  1.2597e-01,  1.5530e+00, -1.7768e+00,\n",
       "         8.8908e-01, -2.0531e-01,  1.3131e+00,  3.3952e-01,  1.0374e+00,\n",
       "         1.8416e-01,  3.7972e+00, -3.4437e-01,  1.2769e+00,  5.5517e-01,\n",
       "        -8.9504e-02, -1.0492e-01, -2.1333e-01,  2.8556e+00, -1.1283e+00])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[33,  9, 32, 47],\n",
       "        [79, 80, 48, 96],\n",
       "        [33, 42, 52, 39],\n",
       "        [46, 71, 25, 51],\n",
       "        [10, 23, 72, 46],\n",
       "        [40, 48, 26, 94],\n",
       "        [56, 65, 75, 11],\n",
       "        [84, 26, 82, 23],\n",
       "        [ 6,  3, 62, 17],\n",
       "        [18, 49,  7, 32],\n",
       "        [40,  7, 27, 84],\n",
       "        [42, 63, 12, 83],\n",
       "        [67, 94,  5, 15],\n",
       "        [31, 89, 72, 72],\n",
       "        [75, 37, 79, 82],\n",
       "        [68,  9,  8, 86],\n",
       "        [72, 86, 40, 84],\n",
       "        [95, 60, 30, 14],\n",
       "        [22, 42,  9, 15],\n",
       "        [51, 85, 20, 76],\n",
       "        [92, 14, 12, 78],\n",
       "        [16, 80, 50, 41],\n",
       "        [19, 42, 77, 80],\n",
       "        [62,  4, 77, 42],\n",
       "        [34, 77, 94, 88],\n",
       "        [67, 85, 62, 45],\n",
       "        [37, 86, 88, 39],\n",
       "        [54, 47, 13, 67],\n",
       "        [38, 89, 17, 50],\n",
       "        [86, 47, 96, 23],\n",
       "        [64, 93, 46,  4],\n",
       "        [67,  5,  8, 80],\n",
       "        [ 5, 14, 74, 64],\n",
       "        [90, 68, 19, 65],\n",
       "        [22,  3, 68, 89],\n",
       "        [39, 68, 43, 37],\n",
       "        [55, 21, 67, 13],\n",
       "        [69, 46, 51, 91],\n",
       "        [20, 23, 59, 95],\n",
       "        [11, 92, 52, 11],\n",
       "        [45, 83, 55, 74],\n",
       "        [86, 37, 90, 60],\n",
       "        [55, 71, 23, 10],\n",
       "        [19,  0, 40, 26],\n",
       "        [ 5, 20, 44, 23],\n",
       "        [96, 30, 14, 21],\n",
       "        [74, 99, 50, 22],\n",
       "        [17, 89, 14, 33],\n",
       "        [88,  1, 15, 17],\n",
       "        [41,  7, 76,  1],\n",
       "        [94, 94, 85, 50],\n",
       "        [37, 71, 42, 41],\n",
       "        [60, 74, 63, 64],\n",
       "        [40, 54,  5, 80],\n",
       "        [ 9, 10, 68, 83],\n",
       "        [20, 93, 95, 93],\n",
       "        [44, 33, 88,  0],\n",
       "        [ 9,  8, 52, 57],\n",
       "        [26, 64, 45, 95],\n",
       "        [77, 76, 55, 11],\n",
       "        [ 1, 61, 73, 83],\n",
       "        [18, 51, 52, 99],\n",
       "        [24, 90, 47, 36],\n",
       "        [84,  5, 64, 35],\n",
       "        [54, 71, 67, 31],\n",
       "        [12, 58, 12, 21],\n",
       "        [66, 83, 28, 32],\n",
       "        [74, 70, 68, 18],\n",
       "        [37, 41, 84, 30],\n",
       "        [48, 52, 45, 11],\n",
       "        [78, 98, 72,  7],\n",
       "        [21, 51, 61, 12],\n",
       "        [23, 54, 60, 71],\n",
       "        [47,  5, 76, 92],\n",
       "        [15, 54, 18, 68],\n",
       "        [81, 90, 40, 38],\n",
       "        [11, 29, 86, 26],\n",
       "        [71, 91, 68, 71],\n",
       "        [72, 20,  8, 92],\n",
       "        [ 0, 11, 13,  0],\n",
       "        [69, 79, 58,  6],\n",
       "        [60, 78, 86, 19],\n",
       "        [63,  0, 84, 47],\n",
       "        [17, 46,  6, 35],\n",
       "        [94, 11, 95,  2],\n",
       "        [64, 97, 78, 99],\n",
       "        [91, 72, 50, 95],\n",
       "        [66, 17, 10, 80],\n",
       "        [44, 35, 47, 29],\n",
       "        [ 8, 52, 41,  8],\n",
       "        [95, 99, 52, 94],\n",
       "        [78, 34, 47, 78],\n",
       "        [15, 64, 70, 88],\n",
       "        [91, 11, 43, 22],\n",
       "        [34, 63, 54,  6],\n",
       "        [58, 40,  8, 53],\n",
       "        [91, 76, 35,  0],\n",
       "        [71, 55, 19, 74],\n",
       "        [55,  8, 14, 83],\n",
       "        [95, 23, 24, 33],\n",
       "        [63, 93, 48, 29],\n",
       "        [11, 17, 28, 88],\n",
       "        [82, 47, 97, 98],\n",
       "        [27, 95, 16, 29],\n",
       "        [87, 66, 67, 20],\n",
       "        [57, 43, 66,  3],\n",
       "        [21, 89, 65, 13],\n",
       "        [72, 64, 60, 94],\n",
       "        [13, 12, 34, 15],\n",
       "        [46, 24, 35, 77],\n",
       "        [72, 38, 52, 13],\n",
       "        [99, 76, 11, 45],\n",
       "        [96, 70,  6, 15],\n",
       "        [52, 90, 14,  8],\n",
       "        [ 2, 20, 39, 32],\n",
       "        [47, 54,  6, 90],\n",
       "        [74, 47, 67, 49],\n",
       "        [38, 98, 22,  8],\n",
       "        [38, 74, 66, 30],\n",
       "        [51, 41, 11, 81],\n",
       "        [87, 75, 83, 74],\n",
       "        [75, 78, 83, 37],\n",
       "        [47, 54,  6, 69],\n",
       "        [40, 36, 25, 57],\n",
       "        [87, 30, 23,  9],\n",
       "        [ 6, 61, 19,  7],\n",
       "        [95, 94, 23, 74],\n",
       "        [82, 75, 66, 76],\n",
       "        [24, 48, 14, 75],\n",
       "        [58, 56, 40,  5],\n",
       "        [17, 54, 91, 81],\n",
       "        [44, 57, 41, 30],\n",
       "        [61, 59, 47, 92],\n",
       "        [10, 11, 13, 67],\n",
       "        [41, 44,  2, 26],\n",
       "        [96, 15, 70, 15],\n",
       "        [65, 25, 94, 32],\n",
       "        [ 0, 13, 61, 63],\n",
       "        [78, 42, 76, 26],\n",
       "        [41, 32, 82, 27],\n",
       "        [76, 43, 78, 81],\n",
       "        [29, 92, 17, 55],\n",
       "        [74, 61, 11, 41],\n",
       "        [ 9, 62, 28, 85],\n",
       "        [23, 24, 36, 94],\n",
       "        [71, 94, 66, 72],\n",
       "        [19, 86, 44, 49],\n",
       "        [33, 37, 22, 38],\n",
       "        [40, 74, 19,  2],\n",
       "        [ 8, 63, 19, 79],\n",
       "        [10, 67, 50, 82],\n",
       "        [85, 44, 27, 52],\n",
       "        [ 0, 38, 87, 19],\n",
       "        [18, 62, 81, 95],\n",
       "        [52, 92, 82, 33],\n",
       "        [40, 51, 10,  4],\n",
       "        [94, 82, 77, 86],\n",
       "        [20, 43, 15,  6],\n",
       "        [68, 63, 85, 58],\n",
       "        [13, 73, 28, 14],\n",
       "        [37, 62, 22, 94],\n",
       "        [63, 60, 99, 28],\n",
       "        [18, 64, 85, 98],\n",
       "        [52,  3, 95, 61],\n",
       "        [62, 60, 20, 39],\n",
       "        [30, 89, 31, 91],\n",
       "        [31, 70, 35, 73],\n",
       "        [45, 54, 89, 85],\n",
       "        [29, 56, 78, 94],\n",
       "        [54, 52, 85, 11],\n",
       "        [ 3, 16, 20, 33],\n",
       "        [93, 55, 54, 18],\n",
       "        [92, 86, 40, 94],\n",
       "        [88, 48, 52, 76],\n",
       "        [60, 40, 66,  1],\n",
       "        [91, 65, 95,  9],\n",
       "        [29,  0, 37, 92],\n",
       "        [90,  2,  3, 25],\n",
       "        [74, 95, 33, 49],\n",
       "        [62, 41, 50, 79],\n",
       "        [84, 56, 18, 22],\n",
       "        [16, 48, 94, 66],\n",
       "        [40, 47, 92, 12],\n",
       "        [84, 56, 92, 19],\n",
       "        [24, 13, 78, 56],\n",
       "        [32,  4, 69, 31],\n",
       "        [68, 19, 17, 89],\n",
       "        [17,  0, 28, 15],\n",
       "        [89, 52, 93,  7],\n",
       "        [40, 73, 79, 95],\n",
       "        [75, 15, 74, 42],\n",
       "        [90, 39, 97, 79],\n",
       "        [76, 16, 13, 73],\n",
       "        [92, 18,  3, 91],\n",
       "        [29, 25, 80, 81],\n",
       "        [55, 77,  8, 91],\n",
       "        [20, 57, 97, 30],\n",
       "        [60, 89, 64, 52],\n",
       "        [52,  2,  5, 87],\n",
       "        [52, 73, 59, 19]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.1850e-01, -2.7126e-01,  1.6726e-02, -2.3817e-01],\n",
       "        [-9.3843e-02,  3.5888e-01,  1.1795e+00, -1.0492e-01],\n",
       "        [ 5.1850e-01, -9.7568e-01,  8.0457e-01,  6.9209e-01],\n",
       "        [-7.6023e-01,  9.8000e-01, -1.4465e+00,  1.1942e+00],\n",
       "        [-1.8753e+00,  3.7592e-01, -1.2233e+00, -7.6023e-01],\n",
       "        [ 3.0936e-01,  1.1795e+00, -1.3537e+00,  5.5517e-01],\n",
       "        [-8.1257e-01,  5.3763e-01, -1.6398e-01,  7.5393e-01],\n",
       "        [-1.7768e+00, -1.3537e+00,  1.2597e-01,  3.7592e-01],\n",
       "        [-3.9178e-02,  2.9347e-01, -1.8288e+00,  1.0094e+00],\n",
       "        [ 1.2251e+00,  1.0296e+00,  1.1563e+00,  1.6726e-02],\n",
       "        [ 3.0936e-01,  1.1563e+00,  7.7615e-01, -1.7768e+00],\n",
       "        [-9.7568e-01, -1.3203e+00,  1.6476e-01,  1.5530e+00],\n",
       "        [ 1.3088e+00,  5.5517e-01, -1.2414e-03,  2.5038e-01],\n",
       "        [-5.5231e-01,  1.0374e+00, -1.2233e+00, -1.2233e+00],\n",
       "        [-1.6398e-01, -8.0841e-01, -9.3843e-02,  1.2597e-01],\n",
       "        [-7.3765e-02, -2.7126e-01,  1.4654e+00, -2.0531e-01],\n",
       "        [-1.2233e+00, -2.0531e-01,  3.0936e-01, -1.7768e+00],\n",
       "        [-8.9504e-02,  1.5632e-01, -6.4988e-01,  5.6198e-01],\n",
       "        [-1.5143e+00, -9.7568e-01, -2.7126e-01,  2.5038e-01],\n",
       "        [ 1.1942e+00,  8.8908e-01, -1.5820e-01,  6.7083e-02],\n",
       "        [-3.4437e-01,  5.6198e-01,  1.6476e-01, -9.6570e-01],\n",
       "        [ 3.1218e-01,  3.5888e-01,  2.0394e-01,  5.4713e-01],\n",
       "        [ 1.9295e-01, -9.7568e-01,  2.4627e-01,  3.5888e-01],\n",
       "        [-1.8288e+00, -4.6815e-01,  2.4627e-01, -9.7568e-01],\n",
       "        [ 8.4310e-01,  2.4627e-01,  5.5517e-01,  3.3952e-01],\n",
       "        [ 1.3088e+00,  8.8908e-01, -1.8288e+00,  4.0454e-02],\n",
       "        [-8.0841e-01, -2.0531e-01,  3.3952e-01,  6.9209e-01],\n",
       "        [-6.8432e-01, -2.3817e-01, -1.5836e+00,  1.3088e+00],\n",
       "        [-1.0547e+00,  1.0374e+00,  1.0094e+00,  2.0394e-01],\n",
       "        [-2.0531e-01, -2.3817e-01, -1.0492e-01,  3.7592e-01],\n",
       "        [-2.0107e+00,  1.2769e+00, -7.6023e-01, -4.6815e-01],\n",
       "        [ 1.3088e+00, -1.2414e-03,  1.4654e+00,  3.5888e-01],\n",
       "        [-1.2414e-03,  5.6198e-01, -6.8889e-01, -2.0107e+00],\n",
       "        [ 1.8416e-01, -7.3765e-02,  1.9295e-01,  5.3763e-01],\n",
       "        [-1.5143e+00,  2.9347e-01, -7.3765e-02,  1.0374e+00],\n",
       "        [ 6.9209e-01, -7.3765e-02, -1.7187e+00, -8.0841e-01],\n",
       "        [-4.9388e-03,  8.2826e-01,  1.3088e+00, -1.5836e+00],\n",
       "        [-7.3893e-01, -7.6023e-01,  1.1942e+00,  3.7972e+00],\n",
       "        [-1.5820e-01,  3.7592e-01,  7.8054e-01, -8.9504e-02],\n",
       "        [ 7.5393e-01, -3.4437e-01,  8.0457e-01,  7.5393e-01],\n",
       "        [ 4.0454e-02,  1.5530e+00, -4.9388e-03, -6.8889e-01],\n",
       "        [-2.0531e-01, -8.0841e-01,  1.8416e-01,  1.5632e-01],\n",
       "        [-4.9388e-03,  9.8000e-01,  3.7592e-01, -1.8753e+00],\n",
       "        [ 1.9295e-01, -7.9326e-02,  3.0936e-01, -1.3537e+00],\n",
       "        [-1.2414e-03, -1.5820e-01, -1.5435e+00,  3.7592e-01],\n",
       "        [-1.0492e-01, -6.4988e-01,  5.6198e-01,  8.2826e-01],\n",
       "        [-6.8889e-01, -1.1283e+00,  2.0394e-01, -1.5143e+00],\n",
       "        [ 1.0094e+00,  1.0374e+00,  5.6198e-01,  5.1850e-01],\n",
       "        [ 3.3952e-01, -6.2997e-01,  2.5038e-01,  1.0094e+00],\n",
       "        [ 5.4713e-01,  1.1563e+00,  6.7083e-02, -6.2997e-01],\n",
       "        [ 5.5517e-01,  5.5517e-01,  8.8908e-01,  2.0394e-01],\n",
       "        [-8.0841e-01,  9.8000e-01, -9.7568e-01,  5.4713e-01],\n",
       "        [ 1.5632e-01, -6.8889e-01, -1.3203e+00, -2.0107e+00],\n",
       "        [ 3.0936e-01, -6.8432e-01, -1.2414e-03,  3.5888e-01],\n",
       "        [-2.7126e-01, -1.8753e+00, -7.3765e-02,  1.5530e+00],\n",
       "        [-1.5820e-01,  1.2769e+00, -8.9504e-02,  1.2769e+00],\n",
       "        [-1.5435e+00,  5.1850e-01,  3.3952e-01, -7.9326e-02],\n",
       "        [-2.7126e-01,  1.4654e+00,  8.0457e-01, -1.9065e-01],\n",
       "        [-1.3537e+00, -2.0107e+00,  4.0454e-02, -8.9504e-02],\n",
       "        [ 2.4627e-01,  6.7083e-02, -4.9388e-03,  7.5393e-01],\n",
       "        [-6.2997e-01,  6.7083e-01,  1.0147e+00,  1.5530e+00],\n",
       "        [ 1.2251e+00,  1.1942e+00,  8.0457e-01, -1.1283e+00],\n",
       "        [-1.2277e-01,  1.8416e-01, -2.3817e-01,  1.5605e-01],\n",
       "        [-1.7768e+00, -1.2414e-03, -2.0107e+00, -9.1750e-01],\n",
       "        [-6.8432e-01,  9.8000e-01,  1.3088e+00, -5.5231e-01],\n",
       "        [ 1.6476e-01,  6.7450e-02,  1.6476e-01,  8.2826e-01],\n",
       "        [-4.7031e-01,  1.5530e+00, -5.9863e-01,  1.6726e-02],\n",
       "        [-6.8889e-01,  1.4691e+00, -7.3765e-02,  1.2251e+00],\n",
       "        [-8.0841e-01,  5.4713e-01, -1.7768e+00, -6.4988e-01],\n",
       "        [ 1.1795e+00,  8.0457e-01,  4.0454e-02,  7.5393e-01],\n",
       "        [-9.6570e-01,  2.8556e+00, -1.2233e+00,  1.1563e+00],\n",
       "        [ 8.2826e-01,  1.1942e+00,  6.7083e-01,  1.6476e-01],\n",
       "        [ 3.7592e-01, -6.8432e-01,  1.5632e-01,  9.8000e-01],\n",
       "        [-2.3817e-01, -1.2414e-03,  6.7083e-02, -3.4437e-01],\n",
       "        [ 2.5038e-01, -6.8432e-01,  1.2251e+00, -7.3765e-02],\n",
       "        [ 1.4798e+00,  1.8416e-01,  3.0936e-01, -1.0547e+00],\n",
       "        [ 7.5393e-01,  2.5851e-03, -2.0531e-01, -1.3537e+00],\n",
       "        [ 9.8000e-01,  3.7972e+00, -7.3765e-02,  9.8000e-01],\n",
       "        [-1.2233e+00, -1.5820e-01,  1.4654e+00, -3.4437e-01],\n",
       "        [-7.9326e-02,  7.5393e-01, -1.5836e+00, -7.9326e-02],\n",
       "        [-7.3893e-01, -9.3843e-02,  6.7450e-02, -3.9178e-02],\n",
       "        [ 1.5632e-01, -9.6570e-01, -2.0531e-01,  1.9295e-01],\n",
       "        [-1.3203e+00, -7.9326e-02, -1.7768e+00, -2.3817e-01],\n",
       "        [ 1.0094e+00, -7.6023e-01, -3.9178e-02, -9.1750e-01],\n",
       "        [ 5.5517e-01,  7.5393e-01, -8.9504e-02, -3.7863e-01],\n",
       "        [-2.0107e+00, -2.1333e-01, -9.6570e-01, -1.1283e+00],\n",
       "        [ 3.7972e+00, -1.2233e+00,  2.0394e-01, -8.9504e-02],\n",
       "        [-4.7031e-01,  1.0094e+00, -1.8753e+00,  3.5888e-01],\n",
       "        [-1.5435e+00, -9.1750e-01, -2.3817e-01,  2.5851e-03],\n",
       "        [ 1.4654e+00,  8.0457e-01,  5.4713e-01,  1.4654e+00],\n",
       "        [-8.9504e-02, -1.1283e+00,  8.0457e-01,  5.5517e-01],\n",
       "        [-9.6570e-01,  8.4310e-01, -2.3817e-01, -9.6570e-01],\n",
       "        [ 2.5038e-01, -2.0107e+00,  1.4691e+00,  3.3952e-01],\n",
       "        [ 3.7972e+00,  7.5393e-01, -1.7187e+00, -1.5143e+00],\n",
       "        [ 8.4310e-01, -1.3203e+00, -6.8432e-01, -3.9178e-02],\n",
       "        [ 6.7450e-02,  3.0936e-01,  1.4654e+00,  3.0606e-01],\n",
       "        [ 3.7972e+00,  6.7083e-02, -9.1750e-01, -7.9326e-02],\n",
       "        [ 9.8000e-01, -4.9388e-03,  1.9295e-01, -6.8889e-01],\n",
       "        [-4.9388e-03,  1.4654e+00,  5.6198e-01,  1.5530e+00],\n",
       "        [-8.9504e-02,  3.7592e-01, -1.2277e-01,  5.1850e-01],\n",
       "        [-1.3203e+00,  1.2769e+00,  1.1795e+00,  2.5851e-03],\n",
       "        [ 7.5393e-01,  1.0094e+00, -5.9863e-01,  3.3952e-01],\n",
       "        [ 1.2597e-01, -2.3817e-01, -2.1333e-01,  2.8556e+00],\n",
       "        [ 7.7615e-01, -8.9504e-02,  3.1218e-01,  2.5851e-03],\n",
       "        [ 1.3131e+00, -4.7031e-01,  1.3088e+00, -1.5820e-01],\n",
       "        [-1.9065e-01, -1.7187e+00, -4.7031e-01,  2.9347e-01],\n",
       "        [ 8.2826e-01,  1.0374e+00,  5.3763e-01, -1.5836e+00],\n",
       "        [-1.2233e+00, -2.0107e+00,  1.5632e-01,  5.5517e-01],\n",
       "        [-1.5836e+00,  1.6476e-01,  8.4310e-01,  2.5038e-01],\n",
       "        [-7.6023e-01, -1.2277e-01, -9.1750e-01,  2.4627e-01],\n",
       "        [-1.2233e+00, -1.0547e+00,  8.0457e-01, -1.5836e+00],\n",
       "        [-1.1283e+00,  6.7083e-02,  7.5393e-01,  4.0454e-02],\n",
       "        [-1.0492e-01,  1.4691e+00, -3.9178e-02,  2.5038e-01],\n",
       "        [ 8.0457e-01,  1.8416e-01,  5.6198e-01,  1.4654e+00],\n",
       "        [-3.7863e-01, -1.5820e-01,  6.9209e-01,  1.6726e-02],\n",
       "        [-2.3817e-01, -6.8432e-01, -3.9178e-02,  1.8416e-01],\n",
       "        [-6.8889e-01, -2.3817e-01,  1.3088e+00,  1.0296e+00],\n",
       "        [-1.0547e+00,  2.8556e+00, -1.5143e+00,  1.4654e+00],\n",
       "        [-1.0547e+00, -6.8889e-01, -4.7031e-01, -6.4988e-01],\n",
       "        [ 1.1942e+00,  5.4713e-01,  7.5393e-01,  1.4798e+00],\n",
       "        [ 1.3131e+00, -1.6398e-01,  1.5530e+00, -6.8889e-01],\n",
       "        [-1.6398e-01, -9.6570e-01,  1.5530e+00, -8.0841e-01],\n",
       "        [-2.3817e-01, -6.8432e-01, -3.9178e-02, -7.3893e-01],\n",
       "        [ 3.0936e-01,  1.5605e-01, -1.4465e+00, -1.9065e-01],\n",
       "        [ 1.3131e+00, -6.4988e-01,  3.7592e-01, -2.7126e-01],\n",
       "        [-3.9178e-02,  6.7083e-01,  1.9295e-01,  1.1563e+00],\n",
       "        [-8.9504e-02,  5.5517e-01,  3.7592e-01, -6.8889e-01],\n",
       "        [ 1.2597e-01, -1.6398e-01, -4.7031e-01,  6.7083e-02],\n",
       "        [-1.2277e-01,  1.1795e+00,  5.6198e-01, -1.6398e-01],\n",
       "        [ 6.7450e-02, -8.1257e-01,  3.0936e-01, -1.2414e-03],\n",
       "        [ 1.0094e+00, -6.8432e-01,  3.7972e+00,  1.4798e+00],\n",
       "        [-1.5435e+00, -1.9065e-01,  5.4713e-01, -6.4988e-01],\n",
       "        [ 6.7083e-01,  7.8054e-01, -2.3817e-01, -3.4437e-01],\n",
       "        [-1.8753e+00,  7.5393e-01, -1.5836e+00,  1.3088e+00],\n",
       "        [ 5.4713e-01, -1.5435e+00, -3.7863e-01, -1.3537e+00],\n",
       "        [-1.0492e-01,  2.5038e-01,  1.4691e+00,  2.5038e-01],\n",
       "        [ 5.3763e-01, -1.4465e+00,  5.5517e-01,  1.6726e-02],\n",
       "        [-7.9326e-02, -1.5836e+00,  6.7083e-01, -1.3203e+00],\n",
       "        [-9.6570e-01, -9.7568e-01,  6.7083e-02, -1.3537e+00],\n",
       "        [ 5.4713e-01,  1.6726e-02,  1.2597e-01,  7.7615e-01],\n",
       "        [ 6.7083e-02, -1.7187e+00, -9.6570e-01,  1.4798e+00],\n",
       "        [ 2.5851e-03, -3.4437e-01,  1.0094e+00, -4.9388e-03],\n",
       "        [-6.8889e-01,  6.7083e-01,  7.5393e-01,  5.4713e-01],\n",
       "        [-2.7126e-01, -1.8288e+00, -5.9863e-01,  8.8908e-01],\n",
       "        [ 3.7592e-01, -1.2277e-01,  1.5605e-01,  5.5517e-01],\n",
       "        [ 9.8000e-01,  5.5517e-01, -4.7031e-01, -1.2233e+00],\n",
       "        [ 1.9295e-01, -2.0531e-01, -1.5435e+00,  1.0296e+00],\n",
       "        [ 5.1850e-01, -8.0841e-01, -1.5143e+00, -1.0547e+00],\n",
       "        [ 3.0936e-01, -6.8889e-01,  1.9295e-01, -3.7863e-01],\n",
       "        [ 1.4654e+00, -1.3203e+00,  1.9295e-01, -9.3843e-02],\n",
       "        [-1.8753e+00,  1.3088e+00,  2.0394e-01,  1.2597e-01],\n",
       "        [ 8.8908e-01, -1.5435e+00,  7.7615e-01,  8.0457e-01],\n",
       "        [-7.9326e-02, -1.0547e+00,  1.3131e+00,  1.9295e-01],\n",
       "        [ 1.2251e+00, -1.8288e+00,  1.4798e+00, -8.9504e-02],\n",
       "        [ 8.0457e-01, -3.4437e-01,  1.2597e-01,  5.1850e-01],\n",
       "        [ 3.0936e-01,  1.1942e+00, -1.8753e+00, -4.6815e-01],\n",
       "        [ 5.5517e-01,  1.2597e-01,  2.4627e-01, -2.0531e-01],\n",
       "        [-1.5820e-01, -1.7187e+00,  2.5038e-01, -3.9178e-02],\n",
       "        [-7.3765e-02, -1.3203e+00,  8.8908e-01,  6.7450e-02],\n",
       "        [-1.5836e+00,  1.0147e+00, -5.9863e-01,  5.6198e-01],\n",
       "        [-8.0841e-01, -1.8288e+00, -1.5143e+00,  5.5517e-01],\n",
       "        [-1.3203e+00,  1.5632e-01, -1.1283e+00, -5.9863e-01],\n",
       "        [ 1.2251e+00, -2.0107e+00,  8.8908e-01,  2.8556e+00],\n",
       "        [ 8.0457e-01,  2.9347e-01, -8.9504e-02,  6.7083e-01],\n",
       "        [-1.8288e+00,  1.5632e-01, -1.5820e-01,  6.9209e-01],\n",
       "        [-6.4988e-01,  1.0374e+00, -5.5231e-01,  3.7972e+00],\n",
       "        [-5.5231e-01,  1.4691e+00, -9.1750e-01,  1.0147e+00],\n",
       "        [ 4.0454e-02, -6.8432e-01,  1.0374e+00,  8.8908e-01],\n",
       "        [ 2.5851e-03, -8.1257e-01, -9.6570e-01,  5.5517e-01],\n",
       "        [-6.8432e-01,  8.0457e-01,  8.8908e-01,  7.5393e-01],\n",
       "        [ 2.9347e-01,  3.1218e-01, -1.5820e-01,  5.1850e-01],\n",
       "        [ 1.2769e+00, -4.9388e-03, -6.8432e-01,  1.2251e+00],\n",
       "        [-3.4437e-01, -2.0531e-01,  3.0936e-01,  5.5517e-01],\n",
       "        [ 3.3952e-01,  1.1795e+00,  8.0457e-01,  6.7083e-02],\n",
       "        [ 1.5632e-01,  3.0936e-01, -4.7031e-01, -6.2997e-01],\n",
       "        [ 3.7972e+00,  5.3763e-01, -8.9504e-02, -2.7126e-01],\n",
       "        [ 2.5851e-03, -7.9326e-02, -8.0841e-01, -3.4437e-01],\n",
       "        [ 1.8416e-01, -3.7863e-01,  2.9347e-01, -1.4465e+00],\n",
       "        [-6.8889e-01, -8.9504e-02,  5.1850e-01,  1.0296e+00],\n",
       "        [-1.8288e+00,  5.4713e-01,  2.0394e-01, -9.3843e-02],\n",
       "        [-1.7768e+00, -8.1257e-01,  1.2251e+00, -1.5143e+00],\n",
       "        [ 3.1218e-01,  1.1795e+00,  5.5517e-01, -4.7031e-01],\n",
       "        [ 3.0936e-01, -2.3817e-01, -3.4437e-01,  1.6476e-01],\n",
       "        [-1.7768e+00, -8.1257e-01, -3.4437e-01,  1.9295e-01],\n",
       "        [-1.2277e-01, -1.5836e+00, -9.6570e-01, -8.1257e-01],\n",
       "        [ 1.6726e-02, -4.6815e-01, -7.3893e-01, -5.5231e-01],\n",
       "        [-7.3765e-02,  1.9295e-01,  1.0094e+00,  1.0374e+00],\n",
       "        [ 1.0094e+00, -7.9326e-02, -5.9863e-01,  2.5038e-01],\n",
       "        [ 1.0374e+00,  8.0457e-01,  1.2769e+00,  1.1563e+00],\n",
       "        [ 3.0936e-01,  1.0147e+00, -9.3843e-02, -8.9504e-02],\n",
       "        [-1.6398e-01,  2.5038e-01, -6.8889e-01, -9.7568e-01],\n",
       "        [ 1.8416e-01,  6.9209e-01, -2.1333e-01, -9.3843e-02],\n",
       "        [ 6.7083e-02,  3.1218e-01, -1.5836e+00,  1.0147e+00],\n",
       "        [-3.4437e-01,  1.2251e+00,  2.9347e-01,  3.7972e+00],\n",
       "        [ 2.5851e-03, -1.4465e+00,  3.5888e-01,  1.4798e+00],\n",
       "        [-4.9388e-03,  2.4627e-01,  1.4654e+00,  3.7972e+00],\n",
       "        [-1.5820e-01, -1.9065e-01, -2.1333e-01, -6.4988e-01],\n",
       "        [ 1.5632e-01,  1.0374e+00, -2.0107e+00,  8.0457e-01],\n",
       "        [ 8.0457e-01, -3.7863e-01, -1.2414e-03,  1.3131e+00],\n",
       "        [ 8.0457e-01,  1.0147e+00,  7.8054e-01,  1.9295e-01]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.take(m[0], encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 4])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.take(m[0], encoding).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.6028e-04,  4.1675e-03, -2.8169e-01,  1.2870e+00, -6.5559e-01,\n",
       "        -2.7422e-01,  5.4010e-02,  1.1390e-01,  2.1225e-02,  2.4396e-02,\n",
       "        -4.9330e-01,  3.2960e-01, -2.2585e-04, -8.5741e-01, -1.5671e-03,\n",
       "        -6.0202e-03, -1.3805e-01,  5.1098e-03, -1.0035e-01, -1.1268e-02,\n",
       "         3.0792e-02,  1.2501e-02, -1.6638e-02, -2.0572e-01,  3.9136e-02,\n",
       "        -8.6092e-02,  3.9000e-02, -3.3781e-01, -2.2525e-01, -1.9286e-03,\n",
       "        -9.1374e-01, -8.5449e-04, -9.6634e-04, -1.4092e-03,  3.4008e-02,\n",
       "        -7.0933e-02,  8.4785e-03,  2.5474e+00,  4.1546e-03, -1.5749e-01,\n",
       "         2.1376e-04,  4.7780e-03,  3.4120e-03,  6.4099e-03, -1.1395e-04,\n",
       "         3.1736e-02, -2.4003e-01,  3.0513e-01, -5.4056e-02, -2.6736e-02,\n",
       "         5.5885e-02,  4.2292e-01, -2.8587e-01,  9.4316e-05, -5.8276e-02,\n",
       "         2.3085e-02,  2.1555e-02,  6.0974e-02, -9.8555e-03, -6.1514e-05,\n",
       "        -6.6597e-01, -1.3281e+00,  8.4027e-04,  4.0690e-03,  4.8479e-01,\n",
       "         1.5165e-03,  7.3134e-03,  9.1457e-02, -5.1072e-01,  2.8942e-02,\n",
       "         3.9006e+00,  1.0932e-01, -3.9409e-02, -6.8302e-06,  1.5484e-02,\n",
       "        -8.8917e-02,  5.4169e-04, -2.6901e-01, -9.7657e-02, -7.5127e-03,\n",
       "        -1.8324e-04,  5.9801e-03,  4.4319e-02, -2.7583e-02,  1.4184e-02,\n",
       "         4.6736e-01,  8.4788e-02,  3.1950e-01, -8.7194e-04,  9.4532e-01,\n",
       "         4.5106e-02, -1.8726e-01, -2.5111e-01,  7.4507e+00, -2.9843e-02,\n",
       "         9.3586e-03,  1.8540e-02,  6.4334e-04, -6.3167e-03,  2.1417e-03,\n",
       "        -5.1400e-03, -1.5467e-01,  1.8276e-02, -5.6063e-05,  1.2787e-01,\n",
       "        -4.5227e-02, -7.3156e-01,  2.1346e-01, -5.5076e-02, -2.1088e-02,\n",
       "        -1.6439e+00, -2.3084e-03,  1.5119e-03,  1.2202e-01,  6.9335e-04,\n",
       "        -1.1759e-03,  2.2111e-01,  6.6834e+00,  2.2208e-01,  7.2895e-01,\n",
       "         2.3038e-01, -1.9882e-01,  4.7183e-03,  1.3313e-02,  8.7022e-02,\n",
       "        -5.8637e-03,  1.2868e-02,  6.5173e-04,  1.3344e-02,  2.1048e-05,\n",
       "        -3.8813e+00, -1.0463e-01,  4.2946e-02,  2.9304e+00, -4.3286e-01,\n",
       "        -9.6625e-03, -7.2211e-03, -1.1126e-01, -8.5564e-02,  8.9471e-04,\n",
       "         1.6476e-01,  4.4380e-06, -1.9063e-01, -2.6404e-01, -3.9983e-03,\n",
       "         3.1301e-01,  6.2959e-02, -6.6945e-01,  1.5569e-02,  3.5032e-02,\n",
       "        -6.3055e-02, -8.5697e-01,  2.1199e-02,  2.9674e-01, -1.8096e-02,\n",
       "         3.2434e-01, -3.5359e-03, -2.6671e-03,  5.8403e-03,  5.4059e-01,\n",
       "        -1.2429e+00, -1.3939e-01, -6.2540e+00, -1.4177e-02,  3.1300e-02,\n",
       "         1.4140e+00,  7.5539e-01, -2.5534e-02,  1.1262e-03, -3.6906e-01,\n",
       "        -7.5148e-03,  5.2869e-03,  1.2143e-02,  2.1613e-02,  1.4328e-02,\n",
       "         4.9565e-02, -5.7089e-05,  2.9599e-02,  3.2917e-02,  1.9150e-02,\n",
       "        -2.6783e+00, -9.6140e-02,  4.1804e-03, -9.5932e-02,  1.5256e-01,\n",
       "        -3.1956e-03, -1.4904e-02,  1.2001e-02,  1.2324e+00,  2.6366e-03,\n",
       "        -2.7597e-02,  2.5515e-03, -3.3652e-02, -4.7015e-01, -1.9858e-03,\n",
       "        -6.7679e-03,  4.1812e-03, -2.6235e-01,  4.9659e-04,  1.2295e-01])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\\prod_{ l \\in {\\cal L} (\\mu) \\ j } m_{\\mu j}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.take(m[0], encoding).prod(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[33,  9, 32, 47],\n",
       "        [79, 80, 48, 96],\n",
       "        [33, 42, 52, 39],\n",
       "        [46, 71, 25, 51],\n",
       "        [10, 23, 72, 46],\n",
       "        [40, 48, 26, 94],\n",
       "        [56, 65, 75, 11],\n",
       "        [84, 26, 82, 23],\n",
       "        [ 6,  3, 62, 17],\n",
       "        [18, 49,  7, 32],\n",
       "        [40,  7, 27, 84],\n",
       "        [42, 63, 12, 83],\n",
       "        [67, 94,  5, 15],\n",
       "        [31, 89, 72, 72],\n",
       "        [75, 37, 79, 82],\n",
       "        [68,  9,  8, 86],\n",
       "        [72, 86, 40, 84],\n",
       "        [95, 60, 30, 14],\n",
       "        [22, 42,  9, 15],\n",
       "        [51, 85, 20, 76],\n",
       "        [92, 14, 12, 78],\n",
       "        [16, 80, 50, 41],\n",
       "        [19, 42, 77, 80],\n",
       "        [62,  4, 77, 42],\n",
       "        [34, 77, 94, 88],\n",
       "        [67, 85, 62, 45],\n",
       "        [37, 86, 88, 39],\n",
       "        [54, 47, 13, 67],\n",
       "        [38, 89, 17, 50],\n",
       "        [86, 47, 96, 23],\n",
       "        [64, 93, 46,  4],\n",
       "        [67,  5,  8, 80],\n",
       "        [ 5, 14, 74, 64],\n",
       "        [90, 68, 19, 65],\n",
       "        [22,  3, 68, 89],\n",
       "        [39, 68, 43, 37],\n",
       "        [55, 21, 67, 13],\n",
       "        [69, 46, 51, 91],\n",
       "        [20, 23, 59, 95],\n",
       "        [11, 92, 52, 11],\n",
       "        [45, 83, 55, 74],\n",
       "        [86, 37, 90, 60],\n",
       "        [55, 71, 23, 10],\n",
       "        [19,  0, 40, 26],\n",
       "        [ 5, 20, 44, 23],\n",
       "        [96, 30, 14, 21],\n",
       "        [74, 99, 50, 22],\n",
       "        [17, 89, 14, 33],\n",
       "        [88,  1, 15, 17],\n",
       "        [41,  7, 76,  1],\n",
       "        [94, 94, 85, 50],\n",
       "        [37, 71, 42, 41],\n",
       "        [60, 74, 63, 64],\n",
       "        [40, 54,  5, 80],\n",
       "        [ 9, 10, 68, 83],\n",
       "        [20, 93, 95, 93],\n",
       "        [44, 33, 88,  0],\n",
       "        [ 9,  8, 52, 57],\n",
       "        [26, 64, 45, 95],\n",
       "        [77, 76, 55, 11],\n",
       "        [ 1, 61, 73, 83],\n",
       "        [18, 51, 52, 99],\n",
       "        [24, 90, 47, 36],\n",
       "        [84,  5, 64, 35],\n",
       "        [54, 71, 67, 31],\n",
       "        [12, 58, 12, 21],\n",
       "        [66, 83, 28, 32],\n",
       "        [74, 70, 68, 18],\n",
       "        [37, 41, 84, 30],\n",
       "        [48, 52, 45, 11],\n",
       "        [78, 98, 72,  7],\n",
       "        [21, 51, 61, 12],\n",
       "        [23, 54, 60, 71],\n",
       "        [47,  5, 76, 92],\n",
       "        [15, 54, 18, 68],\n",
       "        [81, 90, 40, 38],\n",
       "        [11, 29, 86, 26],\n",
       "        [71, 91, 68, 71],\n",
       "        [72, 20,  8, 92],\n",
       "        [ 0, 11, 13,  0],\n",
       "        [69, 79, 58,  6],\n",
       "        [60, 78, 86, 19],\n",
       "        [63,  0, 84, 47],\n",
       "        [17, 46,  6, 35],\n",
       "        [94, 11, 95,  2],\n",
       "        [64, 97, 78, 99],\n",
       "        [91, 72, 50, 95],\n",
       "        [66, 17, 10, 80],\n",
       "        [44, 35, 47, 29],\n",
       "        [ 8, 52, 41,  8],\n",
       "        [95, 99, 52, 94],\n",
       "        [78, 34, 47, 78],\n",
       "        [15, 64, 70, 88],\n",
       "        [91, 11, 43, 22],\n",
       "        [34, 63, 54,  6],\n",
       "        [58, 40,  8, 53],\n",
       "        [91, 76, 35,  0],\n",
       "        [71, 55, 19, 74],\n",
       "        [55,  8, 14, 83],\n",
       "        [95, 23, 24, 33],\n",
       "        [63, 93, 48, 29],\n",
       "        [11, 17, 28, 88],\n",
       "        [82, 47, 97, 98],\n",
       "        [27, 95, 16, 29],\n",
       "        [87, 66, 67, 20],\n",
       "        [57, 43, 66,  3],\n",
       "        [21, 89, 65, 13],\n",
       "        [72, 64, 60, 94],\n",
       "        [13, 12, 34, 15],\n",
       "        [46, 24, 35, 77],\n",
       "        [72, 38, 52, 13],\n",
       "        [99, 76, 11, 45],\n",
       "        [96, 70,  6, 15],\n",
       "        [52, 90, 14,  8],\n",
       "        [ 2, 20, 39, 32],\n",
       "        [47, 54,  6, 90],\n",
       "        [74, 47, 67, 49],\n",
       "        [38, 98, 22,  8],\n",
       "        [38, 74, 66, 30],\n",
       "        [51, 41, 11, 81],\n",
       "        [87, 75, 83, 74],\n",
       "        [75, 78, 83, 37],\n",
       "        [47, 54,  6, 69],\n",
       "        [40, 36, 25, 57],\n",
       "        [87, 30, 23,  9],\n",
       "        [ 6, 61, 19,  7],\n",
       "        [95, 94, 23, 74],\n",
       "        [82, 75, 66, 76],\n",
       "        [24, 48, 14, 75],\n",
       "        [58, 56, 40,  5],\n",
       "        [17, 54, 91, 81],\n",
       "        [44, 57, 41, 30],\n",
       "        [61, 59, 47, 92],\n",
       "        [10, 11, 13, 67],\n",
       "        [41, 44,  2, 26],\n",
       "        [96, 15, 70, 15],\n",
       "        [65, 25, 94, 32],\n",
       "        [ 0, 13, 61, 63],\n",
       "        [78, 42, 76, 26],\n",
       "        [41, 32, 82, 27],\n",
       "        [76, 43, 78, 81],\n",
       "        [29, 92, 17, 55],\n",
       "        [74, 61, 11, 41],\n",
       "        [ 9, 62, 28, 85],\n",
       "        [23, 24, 36, 94],\n",
       "        [71, 94, 66, 72],\n",
       "        [19, 86, 44, 49],\n",
       "        [33, 37, 22, 38],\n",
       "        [40, 74, 19,  2],\n",
       "        [ 8, 63, 19, 79],\n",
       "        [10, 67, 50, 82],\n",
       "        [85, 44, 27, 52],\n",
       "        [ 0, 38, 87, 19],\n",
       "        [18, 62, 81, 95],\n",
       "        [52, 92, 82, 33],\n",
       "        [40, 51, 10,  4],\n",
       "        [94, 82, 77, 86],\n",
       "        [20, 43, 15,  6],\n",
       "        [68, 63, 85, 58],\n",
       "        [13, 73, 28, 14],\n",
       "        [37, 62, 22, 94],\n",
       "        [63, 60, 99, 28],\n",
       "        [18, 64, 85, 98],\n",
       "        [52,  3, 95, 61],\n",
       "        [62, 60, 20, 39],\n",
       "        [30, 89, 31, 91],\n",
       "        [31, 70, 35, 73],\n",
       "        [45, 54, 89, 85],\n",
       "        [29, 56, 78, 94],\n",
       "        [54, 52, 85, 11],\n",
       "        [ 3, 16, 20, 33],\n",
       "        [93, 55, 54, 18],\n",
       "        [92, 86, 40, 94],\n",
       "        [88, 48, 52, 76],\n",
       "        [60, 40, 66,  1],\n",
       "        [91, 65, 95,  9],\n",
       "        [29,  0, 37, 92],\n",
       "        [90,  2,  3, 25],\n",
       "        [74, 95, 33, 49],\n",
       "        [62, 41, 50, 79],\n",
       "        [84, 56, 18, 22],\n",
       "        [16, 48, 94, 66],\n",
       "        [40, 47, 92, 12],\n",
       "        [84, 56, 92, 19],\n",
       "        [24, 13, 78, 56],\n",
       "        [32,  4, 69, 31],\n",
       "        [68, 19, 17, 89],\n",
       "        [17,  0, 28, 15],\n",
       "        [89, 52, 93,  7],\n",
       "        [40, 73, 79, 95],\n",
       "        [75, 15, 74, 42],\n",
       "        [90, 39, 97, 79],\n",
       "        [76, 16, 13, 73],\n",
       "        [92, 18,  3, 91],\n",
       "        [29, 25, 80, 81],\n",
       "        [55, 77,  8, 91],\n",
       "        [20, 57, 97, 30],\n",
       "        [60, 89, 64, 52],\n",
       "        [52,  2,  5, 87],\n",
       "        [52, 73, 59, 19]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
