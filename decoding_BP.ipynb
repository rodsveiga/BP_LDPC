{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding with Belief Propagation\n",
    "\n",
    "We want to iterate the following the following equations:\n",
    "\n",
    "$$ \\hat{m}_{\\mu j} = \\tanh ( \\beta(\\rho) J_\\mu ) \\prod_{ l \\in {\\cal L} (\\mu) \\backslash j } m_{\\mu l}  \\; \\; ,  $$ \n",
    "\n",
    "$$ m_{\\mu j} = \\tanh \\left(  \\sum_{ \\nu \\in {\\cal M} (j) \\backslash \\mu } \\ \\tanh^{-1} \\left(  \\hat{m}_{\\nu j}  \\right)    + \\beta(\\rho_\\xi)  \\right)   \\; \\; ,  $$  \n",
    "\n",
    "which are Eqs.(96) from the paper [Low-density parity-check codesâ€”A statistical physics perspective](https://www.sciencedirect.com/science/article/pii/S1076567002800180), by R. Vicente, D. Saad and Y. Kabashima.\n",
    "\n",
    "The function $ \\beta(x) $ is the Nishimori temperature,\n",
    "\n",
    "$$ \\beta(x) = \\frac{1}{2} \\log \\left(  \\frac{1- \\rho}{\\rho}  \\right) \\; \\; .  $$\n",
    "\n",
    "The quantity $\\rho$ is the flip probablility of the noisy channel (BSC),\n",
    "\n",
    "$$ P ( J | J^{(0)} ) = (1 - \\rho) \\delta_{J, J^{(0)} } + \\rho \\delta_{J, -J^{(0)} }   \\; \\; , $$\n",
    "\n",
    "whereas the prior distribution for each meassage bit is assumed to be\n",
    "\n",
    "$$ P ( S_j ) = (1 - \\rho_\\xi) \\delta_{+1, S_j }  +  \\rho_\\xi \\delta_{-1, S_j }  \\; \\; .  $$\n",
    "\n",
    "The object $ {\\cal L} (\\mu)$ represents the set of $K$ non-zero elements on the row $\\mu$ of the code generator matrix ${\\cal G}$ (the one which adds redundancy), \n",
    "\n",
    "$$  {\\cal L} (\\mu) = \\langle i_1, i_2, ..., i_K \\rangle  \\; \\; .  $$\n",
    "\n",
    "The are $C$ non-zero elements per column on the matrix ${\\cal G}$:\n",
    "\n",
    "$$ \\sum_{\\mu : j \\in {\\cal L}(\\mu)} i_j = C \\; \\; ; \\; \\; \\forall j = 1, ..., K \\; \\; . $$\n",
    "\n",
    "The object $ {\\cal M} (j)$ represents the set of all index sets that contain $j$.\n",
    "\n",
    "After convergence of the iterative procedure, we can calculate the pseudo-posterior:\n",
    "\n",
    "$$ m_{j} = \\tanh \\left(  \\sum_{ \\nu \\in {\\cal M} (j) } \\tanh^{-1} \\left(  \\hat{m}_{\\nu j}  \\right)    + \\beta(\\rho_\\xi)  \\right)   \\; \\; ,  $$\n",
    "from which the Bayes optimal estimate is obtained\n",
    "$$ \\hat{\\xi}_j  = sign( m_j ) $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the variables of the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message lengh\n",
    "N = 100\n",
    "\n",
    "# Codeword lengh\n",
    "M = 200\n",
    "\n",
    "# Non-zero elements per row of the generation matrix\n",
    "K = 4\n",
    "\n",
    "# Number of messages\n",
    "n = 10\n",
    "\n",
    "# Noisy channel\n",
    "p = 0.3\n",
    "beta = 0.5*np.log( (1 - p) / p)\n",
    "\n",
    "# Message prior\n",
    "p_prior = 0.1\n",
    "beta_prior = 0.5*np.log( (1 - p_prior) / p_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating messages\n",
    "\n",
    "Each message is a $N$ dimensional vector. Generate a set of $n$ messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = torch.rand([n, N])\n",
    "    \n",
    "message = torch.zeros([n, N])\n",
    "\n",
    "for j in range(random.shape[0]):\n",
    "    \n",
    "    for k in range(random.shape[1]):\n",
    "               \n",
    "            #### -1 with probability p_prior\n",
    "            if random[j,k] <= p_prior:\n",
    "                message[j,k] = -1.\n",
    "            #### +1 with probability 1 - p_prior\n",
    "            else:\n",
    "                message[j,k] = +1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "Each message is encoded to a high dimensional vector ${\\bf J}^{(0)} \\in \\{ \\pm 1  \\}^M$ defined as \n",
    "\n",
    "$$   J^{(0)}_{\\langle i_1, i_2, ...., i_K \\rangle} = \\xi_1 \\xi_ 2 ... \\xi_K  \\; \\; ,$$\n",
    "\n",
    "where $M$ sets of $K \\in [ 1, ..., N]$ indexes are randomly chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = torch.randint(0, N, [M, K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 4])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From `encoding`, we construct the encoded message ${\\bf J}^{(0)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing\n",
    "J0 = torch.take(message[0], encoding).prod(dim=1)\n",
    "J0 = J0.unsqueeze(0)\n",
    "\n",
    "for j in range(1, message.shape[0]):\n",
    "    \n",
    "    J0_ = torch.take(message[j], encoding).prod(dim=1)\n",
    "    J0_ = J0_.unsqueeze(0)\n",
    "    \n",
    "    J0 = torch.cat((J0, J0_), dim= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrupted version of the encoded set of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = J0.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = torch.rand(J.shape)\n",
    "                      \n",
    "for j in range(J.shape[0]):\n",
    "    for k in range(J.shape[1]):\n",
    "          \n",
    "        if random[j, k] <= p:\n",
    "            J[j, k] = -J[j, k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -1.,  1.,  ...,  1.,  1., -1.],\n",
       "        [-1., -1.,  1.,  ...,  1.,  1., -1.],\n",
       "        [-1.,  1.,  1.,  ..., -1., -1., -1.],\n",
       "        ...,\n",
       "        [ 1.,  1.,  1.,  ...,  1.,  1., -1.],\n",
       "        [ 1., -1.,  1.,  ...,  1.,  1., -1.],\n",
       "        [ 1., -1., -1.,  ..., -1.,  1., -1.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 200])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Flip tensor: -1 with probability p\n",
    "flip = 2*(random > p).float() - 1\n",
    "\n",
    "## J corrupted version: element wise multiplication\n",
    "J_ = torch.mul(J0, flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -1.,  1.,  ...,  1.,  1., -1.],\n",
       "        [ 1., -1.,  1.,  ...,  1.,  1., -1.],\n",
       "        [ 1.,  1.,  1.,  ...,  1., -1., -1.],\n",
       "        ...,\n",
       "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  ...,  1.,  1., -1.],\n",
       "        [-1.,  1., -1.,  ...,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9124, 0.1064, 0.6410,  ..., 0.6197, 0.5000, 0.0101],\n",
       "        [0.4607, 0.0198, 0.5395,  ..., 0.9540, 0.7226, 0.1243],\n",
       "        [0.8156, 0.9868, 0.3049,  ..., 0.6664, 0.1401, 0.2027],\n",
       "        ...,\n",
       "        [0.6110, 0.4401, 0.6442,  ..., 0.5178, 0.8706, 0.9719],\n",
       "        [0.8922, 0.8729, 0.5421,  ..., 0.8211, 0.9470, 0.0958],\n",
       "        [0.1390, 0.5615, 0.2017,  ..., 0.6895, 0.7020, 0.8423]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  ..., False, False,  True],\n",
       "        [False,  True, False,  ..., False, False,  True],\n",
       "        [False, False, False,  ..., False,  True,  True],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False,  True],\n",
       "        [ True, False,  True,  ..., False, False, False]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random <= p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        ...,\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J == J_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating BP equations for one message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us focus in one received message to iterate the belief propagation equations.\n",
    "\n",
    "$$ \\hat{m}_{\\mu j} = \\tanh ( \\beta(\\rho) J_\\mu ) \\prod_{ l \\in {\\cal L} (\\mu) \\backslash j } m_{\\mu l}  \\; \\; ,  $$ \n",
    "\n",
    "$$ m_{\\mu j} = \\tanh \\left(  \\sum_{ \\nu \\in {\\cal M} (j) \\backslash \\mu} \\ \\tanh^{-1} \\left(  \\hat{m}_{\\nu j}  \\right) + \\beta(\\rho_\\xi)    \\right)   \\; \\; ,  $$  \n",
    "\n",
    "with $j = 1, ..., N$ and $\\mu = 1, ..., M$.\n",
    "\n",
    "We cal this message `J_`. We will worry later about a loop over all the received messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,\n",
      "         1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,\n",
      "        -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,\n",
      "         1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,\n",
      "         1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1.,  1.,\n",
      "        -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.,  1.,\n",
      "         1., -1., -1., -1.,  1.,  1., -1.,  1., -1., -1.,  1., -1., -1., -1.,\n",
      "         1., -1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,\n",
      "        -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,\n",
      "        -1., -1.,  1.,  1., -1.,  1., -1., -1., -1., -1.,  1., -1.,  1., -1.,\n",
      "        -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1., -1.,\n",
      "        -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
      "        -1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
      "         1.,  1.,  1.,  1.])\n",
      "torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "J_ = J[0]\n",
    "print(J_)\n",
    "print(J_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random initialization of the beliefs $m_{\\mu l}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.rand(M, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6993, 0.7876, 0.6544,  ..., 0.1501, 0.7978, 0.7293],\n",
       "        [0.8825, 0.2156, 0.6157,  ..., 0.6019, 0.1765, 0.9871],\n",
       "        [0.8097, 0.8887, 0.5504,  ..., 0.5052, 0.8078, 0.1740],\n",
       "        ...,\n",
       "        [0.3305, 0.4320, 0.4681,  ..., 0.8783, 0.2415, 0.5931],\n",
       "        [0.1749, 0.8697, 0.8215,  ..., 0.5397, 0.6670, 0.7277],\n",
       "        [0.5649, 0.5952, 0.6937,  ..., 0.9226, 0.3572, 0.1892]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize an empty tensor to represent $\\hat{m}_{\\mu l}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_hat = torch.empty(M, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to calculate $\\hat{m}_{\\mu j}$.\n",
    "\n",
    "$$ \\hat{m}_{\\mu j} = \\tanh ( \\beta(\\rho) J_\\mu ) \\prod_{ l \\in {\\cal L} (\\mu) \\backslash j } m_{\\mu l}  \\; \\; ,  $$ \n",
    "\n",
    "This first implementation has two `for` loops. This is potentially harmful if one cares about efficienty. We obviously do, but since we are just beginning, lets go on like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mu in range(M):\n",
    "    for j in range(N):\n",
    "          \n",
    "        # Keep only L(mu) which a are different of j\n",
    "        index_no_j = torch.nonzero(encoding[mu] != j).squeeze()\n",
    "        L_no_j = encoding[mu][index_no_j]\n",
    "        \n",
    "        # Message update        \n",
    "        m_hat[mu, j] = torch.tanh( beta* J_[mu])*torch.take(m[mu], L_no_j).prod(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [-0., -0., -0.,  ..., -0., -0., -0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to implement:\n",
    "\n",
    "$$ m_{\\mu j} = \\tanh \\left(  \\sum_{ \\nu \\in {\\cal M} (j) \\backslash \\mu} \\ \\tanh^{-1} \\left(  \\hat{m}_{\\nu j}  \\right) + \\beta(\\rho_\\xi)     \\right)  \\; \\; ,  $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(N):\n",
    "    \n",
    "    for mu in range(M):\n",
    "        \n",
    "        M_set = torch.where(encoding == j)[0]\n",
    "        \n",
    "        M_set_no_mu = M_set[torch.nonzero(M_set != mu).squeeze()]\n",
    "        \n",
    "        m[mu, j] = torch.tanh(torch.take(np.arctanh(m_hat[:, j]), M_set_no_mu).sum() + beta_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8000, 0.8000, 0.8000,  ..., 0.8000, 0.8000, 0.8000],\n",
       "        [0.8000, 0.8000, 0.8000,  ..., 0.8000, 0.8000, 0.8000],\n",
       "        [0.8000, 0.8000, 0.8000,  ..., 0.8000, 0.8000, 0.8000],\n",
       "        ...,\n",
       "        [0.8000, 0.8000, 0.8000,  ..., 0.8000, 0.8000, 0.8000],\n",
       "        [0.8000, 0.8000, 0.8000,  ..., 0.8000, 0.8000, 0.8000],\n",
       "        [0.8000, 0.8000, 0.8000,  ..., 0.8000, 0.8000, 0.8000]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to implement the pseudo-posterior, which is calculated after convergence of the messages above:\n",
    "\n",
    "$$ m_{j} = \\tanh \\left(  \\sum_{ \\nu \\in {\\cal M} (j) } \\tanh^{-1} \\left(  \\hat{m}_{\\nu j}  \\right)    + \\beta(\\rho_\\xi)  \\right)   \\; \\; ,  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_bayes = []\n",
    "\n",
    "for j in range(N):\n",
    "    \n",
    "    M_set = torch.where(encoding == j)[0]\n",
    "       \n",
    "    m_j = torch.tanh(torch.take(np.arctanh(m_hat[:, j]), M_set).sum() + beta_prior)\n",
    "    \n",
    "    m_bayes.append(m_j.item())\n",
    "            \n",
    "m_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m_bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sign(m_bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering all message iterations on functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_to_mhat(N, M, J_, m, beta, encoding):\n",
    "    \n",
    "    m_hat = torch.empty(M, N)\n",
    "    \n",
    "    for mu in range(M):\n",
    "        for j in range(N):\n",
    "                     \n",
    "            # Keep only L(mu) which a are different of j\n",
    "            index_no_j = torch.nonzero(encoding[mu] != j).squeeze()\n",
    "            L_no_j = encoding[mu][index_no_j]\n",
    "        \n",
    "            # Message update        \n",
    "            m_hat[mu, j] = torch.tanh( beta* J_[mu])*torch.take(m[mu], L_no_j).prod(dim=0)\n",
    "            \n",
    "    return m_hat\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "\n",
    "def mhat_to_m(N, M, m_hat, beta_prior, encoding):\n",
    "    \n",
    "    m = torch.empty(M, N)\n",
    "    \n",
    "    for j in range(N):\n",
    "        \n",
    "        for mu in range(M):\n",
    "            \n",
    "            M_set = torch.where(encoding == j)[0]\n",
    "        \n",
    "            M_set_no_mu = M_set[torch.nonzero(M_set != mu).squeeze()]\n",
    "            \n",
    "            m[mu, j] = torch.tanh(torch.take(np.arctanh(m_hat[:, j]), M_set_no_mu).sum() + beta_prior)\n",
    "            \n",
    "    return m\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "\n",
    "def m_bayes(N, m_hat_final, beta_prior, encoding):\n",
    "    \n",
    "    m_bayes = []\n",
    "\n",
    "    for j in range(N):\n",
    "           \n",
    "        M_set = torch.where(encoding == j)[0]\n",
    "  \n",
    "        m_j = torch.tanh(torch.take(np.arctanh(m_hat_final[:, j]), M_set).sum() + beta_prior)\n",
    "    \n",
    "        m_bayes.append(m_j.item())\n",
    "        \n",
    "    return m_bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we construct a function for the iterative decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BP_LDPC(N, M, J_, beta, beta_prior, encoding, message, num_it= 100, verbose= 1):\n",
    "     \n",
    "    m_hat = torch.rand(M, N)\n",
    "    m = torch.empty(M, N)\n",
    "    \n",
    "    for j in range(num_it):\n",
    "        \n",
    "        print('--it = %d' % j)\n",
    "              \n",
    "        m = mhat_to_m(N, M, m_hat, beta_prior, encoding)\n",
    "        m_hat = m_to_mhat(N, M, J_, m, beta, encoding)\n",
    "        \n",
    "        ## Monitoring performace\n",
    "        if (j % verbose) == 0:\n",
    "            m_ = m_bayes(N, m_hat, beta_prior, encoding)\n",
    "            print('overlap= ', torch.dot(message, torch.Tensor(np.sign(m_))).item() / N)\n",
    "        \n",
    "    m_final = m_bayes(N, m_hat, beta_prior, encoding)\n",
    "    \n",
    "    return np.sign(m_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--it = 0\n",
      "overlap=  0.82\n",
      "--it = 1\n",
      "overlap=  0.82\n",
      "--it = 2\n",
      "overlap=  0.82\n",
      "--it = 3\n",
      "overlap=  0.82\n",
      "--it = 4\n",
      "overlap=  0.82\n",
      "--it = 5\n",
      "overlap=  0.82\n",
      "--it = 6\n",
      "overlap=  0.82\n",
      "--it = 7\n",
      "overlap=  0.82\n",
      "--it = 8\n",
      "overlap=  0.82\n",
      "--it = 9\n",
      "overlap=  0.82\n",
      "--it = 10\n",
      "overlap=  0.82\n",
      "--it = 11\n",
      "overlap=  0.82\n",
      "--it = 12\n",
      "overlap=  0.82\n",
      "--it = 13\n",
      "overlap=  0.82\n",
      "--it = 14\n",
      "overlap=  0.82\n",
      "--it = 15\n",
      "overlap=  0.82\n",
      "--it = 16\n",
      "overlap=  0.82\n",
      "--it = 17\n",
      "overlap=  0.82\n",
      "--it = 18\n",
      "overlap=  0.82\n",
      "--it = 19\n",
      "overlap=  0.82\n"
     ]
    }
   ],
   "source": [
    "opt_dec_Bayes = BP_LDPC(N, M, J_, beta, beta_prior, encoding, message[0], num_it= 20, verbose= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. It is still slow (we will worrie about this latter), but it appears to work.\n",
    "\n",
    "Observe that we arbitrarily consider a certain `num_it`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick test on previous codes and messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message lengh\n",
    "N = 250\n",
    "\n",
    "# Codeword lengh\n",
    "M = 500\n",
    "\n",
    "# Non-zero elements per row of the generation matrix\n",
    "K = 4\n",
    "\n",
    "# Number of messages\n",
    "n = 100\n",
    "\n",
    "# Noisy channel\n",
    "p = 0.3\n",
    "beta = 0.5*np.log( (1 - p) / p)\n",
    "\n",
    "# Message prior\n",
    "p_prior = 0.01\n",
    "beta_prior = 0.5*np.log( (1 - p_prior) / p_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = torch.load('codes/code_N_250_M_500_K_4_p_03_p_prior_001_j_0.pt')\n",
    "message = torch.load('codes/message_N_250_M_500_K_4_p_03_p_prior_001.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  ...,  1., -1.,  1.],\n",
       "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
       "        ...,\n",
       "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  ...,  1., -1.,  1.],\n",
      "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
      "        ...,\n",
      "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 250])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(message)\n",
    "message.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we made a mistake saving the codes. We have actually saved the messages. That is a problem. For now, let us generate a new code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 94,  21, 204, 242],\n",
       "        [162,  49, 100, 151],\n",
       "        [230, 198, 123,  57],\n",
       "        ...,\n",
       "        [ 87, 176,   1, 211],\n",
       "        [ 99,  72,  51,  91],\n",
       "        [248, 145, 105, 154]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding  = torch.randint(0, N, [M, K])\n",
    "encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing\n",
    "J0 = torch.take(message[0], encoding).prod(dim=1)\n",
    "J0 = J0.unsqueeze(0)\n",
    "\n",
    "for j in range(1, message.shape[0]):\n",
    "    \n",
    "    J0_ = torch.take(message[j], encoding).prod(dim=1)\n",
    "    J0_ = J0_.unsqueeze(0)\n",
    "    \n",
    "    J0 = torch.cat((J0, J0_), dim= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 500])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(J0)\n",
    "J0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corrupted version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = J0.clone()\n",
    "\n",
    "random = torch.rand(J.shape)\n",
    "                      \n",
    "for j in range(J.shape[0]):\n",
    "    for k in range(J.shape[1]):\n",
    "          \n",
    "        if random[j, k] <= p:\n",
    "            J[j, k] = -J[j, k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1., -1.,  1.,  ...,  1., -1.,  1.],\n",
      "        [-1.,  1., -1.,  ...,  1.,  1.,  1.],\n",
      "        [ 1., -1., -1.,  ..., -1.,  1.,  1.],\n",
      "        ...,\n",
      "        [-1.,  1.,  1.,  ..., -1.,  1.,  1.],\n",
      "        [ 1.,  1., -1.,  ...,  1.,  1., -1.],\n",
      "        [ 1.,  1.,  1.,  ...,  1., -1.,  1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 500])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(J)\n",
    "J.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([250])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "500\n",
      "torch.Size([500, 4])\n",
      "torch.Size([100, 500])\n",
      "torch.Size([100, 250])\n"
     ]
    }
   ],
   "source": [
    "print(N)\n",
    "print(M)\n",
    "print(encoding.shape)\n",
    "print(J.shape)\n",
    "print(message.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----message 0\n",
      "--it = 0\n",
      "overlap=  0.992\n",
      "--it = 1\n",
      "overlap=  0.992\n",
      "--it = 2\n",
      "overlap=  0.992\n",
      "--it = 3\n",
      "overlap=  0.992\n",
      "--it = 4\n",
      "overlap=  0.992\n",
      "--it = 5\n",
      "overlap=  0.992\n",
      "--it = 6\n",
      "overlap=  0.992\n",
      "--it = 7\n",
      "overlap=  0.992\n",
      "--it = 8\n",
      "overlap=  0.992\n",
      "--it = 9\n",
      "overlap=  0.992\n",
      "----message 1\n",
      "--it = 0\n",
      "overlap=  0.984\n",
      "--it = 1\n",
      "overlap=  0.992\n",
      "--it = 2\n",
      "overlap=  0.984\n",
      "--it = 3\n",
      "overlap=  0.984\n",
      "--it = 4\n",
      "overlap=  0.984\n",
      "--it = 5\n",
      "overlap=  0.984\n",
      "--it = 6\n",
      "overlap=  0.984\n",
      "--it = 7\n",
      "overlap=  0.984\n",
      "--it = 8\n",
      "overlap=  0.984\n",
      "--it = 9\n",
      "overlap=  0.984\n",
      "----message 2\n",
      "--it = 0\n",
      "overlap=  0.976\n",
      "--it = 1\n",
      "overlap=  0.976\n",
      "--it = 2\n",
      "overlap=  0.976\n",
      "--it = 3\n",
      "overlap=  0.976\n",
      "--it = 4\n",
      "overlap=  0.976\n",
      "--it = 5\n",
      "overlap=  0.976\n",
      "--it = 6\n",
      "overlap=  0.976\n",
      "--it = 7\n",
      "overlap=  0.976\n",
      "--it = 8\n",
      "overlap=  0.976\n",
      "--it = 9\n",
      "overlap=  0.976\n",
      "----message 3\n",
      "--it = 0\n",
      "overlap=  0.968\n",
      "--it = 1\n",
      "overlap=  0.968\n",
      "--it = 2\n",
      "overlap=  0.968\n",
      "--it = 3\n",
      "overlap=  0.968\n",
      "--it = 4\n",
      "overlap=  0.968\n",
      "--it = 5\n",
      "overlap=  0.968\n",
      "--it = 6\n",
      "overlap=  0.968\n",
      "--it = 7\n",
      "overlap=  0.968\n",
      "--it = 8\n",
      "overlap=  0.968\n",
      "--it = 9\n",
      "overlap=  0.968\n",
      "----message 4\n",
      "--it = 0\n",
      "overlap=  0.992\n",
      "--it = 1\n",
      "overlap=  0.992\n",
      "--it = 2\n",
      "overlap=  0.992\n",
      "--it = 3\n",
      "overlap=  0.992\n",
      "--it = 4\n",
      "overlap=  0.992\n",
      "--it = 5\n",
      "overlap=  0.992\n",
      "--it = 6\n",
      "overlap=  0.992\n",
      "--it = 7\n",
      "overlap=  0.992\n",
      "--it = 8\n",
      "overlap=  0.992\n",
      "--it = 9\n",
      "overlap=  0.992\n",
      "----message 5\n",
      "--it = 0\n",
      "overlap=  0.976\n",
      "--it = 1\n",
      "overlap=  0.976\n",
      "--it = 2\n",
      "overlap=  0.976\n",
      "--it = 3\n",
      "overlap=  0.976\n",
      "--it = 4\n",
      "overlap=  0.976\n",
      "--it = 5\n",
      "overlap=  0.976\n",
      "--it = 6\n",
      "overlap=  0.976\n",
      "--it = 7\n",
      "overlap=  0.976\n",
      "--it = 8\n",
      "overlap=  0.976\n",
      "--it = 9\n",
      "overlap=  0.976\n",
      "----message 6\n",
      "--it = 0\n",
      "overlap=  0.992\n",
      "--it = 1\n",
      "overlap=  0.992\n",
      "--it = 2\n",
      "overlap=  0.992\n",
      "--it = 3\n",
      "overlap=  0.992\n",
      "--it = 4\n",
      "overlap=  0.992\n",
      "--it = 5\n",
      "overlap=  0.992\n",
      "--it = 6\n",
      "overlap=  0.992\n",
      "--it = 7\n",
      "overlap=  0.992\n",
      "--it = 8\n",
      "overlap=  0.992\n",
      "--it = 9\n",
      "overlap=  0.992\n",
      "----message 7\n",
      "--it = 0\n",
      "overlap=  0.968\n",
      "--it = 1\n",
      "overlap=  0.968\n",
      "--it = 2\n",
      "overlap=  0.968\n",
      "--it = 3\n",
      "overlap=  0.968\n",
      "--it = 4\n",
      "overlap=  0.968\n",
      "--it = 5\n",
      "overlap=  0.968\n",
      "--it = 6\n",
      "overlap=  0.968\n",
      "--it = 7\n",
      "overlap=  0.968\n",
      "--it = 8\n",
      "overlap=  0.968\n",
      "--it = 9\n",
      "overlap=  0.968\n",
      "----message 8\n",
      "--it = 0\n",
      "overlap=  0.984\n",
      "--it = 1\n",
      "overlap=  0.984\n",
      "--it = 2\n",
      "overlap=  0.984\n",
      "--it = 3\n",
      "overlap=  0.984\n",
      "--it = 4\n",
      "overlap=  0.984\n",
      "--it = 5\n",
      "overlap=  0.984\n",
      "--it = 6\n",
      "overlap=  0.984\n",
      "--it = 7\n",
      "overlap=  0.984\n",
      "--it = 8\n",
      "overlap=  0.984\n",
      "--it = 9\n",
      "overlap=  0.984\n",
      "----message 9\n",
      "--it = 0\n",
      "overlap=  0.968\n",
      "--it = 1\n",
      "overlap=  0.968\n",
      "--it = 2\n",
      "overlap=  0.968\n",
      "--it = 3\n",
      "overlap=  0.968\n",
      "--it = 4\n",
      "overlap=  0.968\n",
      "--it = 5\n",
      "overlap=  0.968\n",
      "--it = 6\n",
      "overlap=  0.968\n",
      "--it = 7\n",
      "overlap=  0.968\n",
      "--it = 8\n",
      "overlap=  0.968\n",
      "--it = 9\n",
      "overlap=  0.968\n"
     ]
    }
   ],
   "source": [
    "overlap_list = []\n",
    "\n",
    "for k in range(int(J.shape[0] / 10 )):\n",
    "    \n",
    "    print('----message %d' % k)\n",
    "       \n",
    "    opt_dec_Bayes = BP_LDPC(N, M, J[k], beta, beta_prior, encoding, message[k], num_it= 10, verbose= 1)\n",
    "    \n",
    "    overlap_list.append(opt_dec_Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
