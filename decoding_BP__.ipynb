{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding with Belief Propagation - Working to take some for loops out of the game\n",
    "\n",
    "We want to iterate the following the following equations:\n",
    "\n",
    "$$ \\hat{m}_{\\mu j} = \\tanh ( \\beta(\\rho) J_\\mu ) \\prod_{ l \\in {\\cal L} (\\mu) \\backslash j } m_{\\mu l}  \\; \\; ,  $$ \n",
    "\n",
    "$$ m_{\\mu j} = \\tanh \\left(  \\sum_{ \\nu \\in {\\cal M} (j) \\backslash \\mu } \\ \\tanh^{-1} \\left(  \\hat{m}_{\\nu j}  \\right)    + \\beta(\\rho_\\xi)  \\right)   \\; \\; ,  $$  \n",
    "\n",
    "which are Eqs.(96) from the paper [Low-density parity-check codesâ€”A statistical physics perspective](https://www.sciencedirect.com/science/article/pii/S1076567002800180), by R. Vicente, D. Saad and Y. Kabashima.\n",
    "\n",
    "The function $ \\beta(x) $ is the Nishimori temperature,\n",
    "\n",
    "$$ \\beta(x) = \\frac{1}{2} \\log \\left(  \\frac{1- \\rho}{\\rho}  \\right) \\; \\; .  $$\n",
    "\n",
    "The quantity $\\rho$ is the flip probablility of the noisy channel (BSC),\n",
    "\n",
    "$$ P ( J | J^{(0)} ) = (1 - \\rho) \\delta_{J, J^{(0)} } + \\rho \\delta_{J, -J^{(0)} }   \\; \\; , $$\n",
    "\n",
    "whereas the prior distribution for each meassage bit is assumed to be\n",
    "\n",
    "$$ P ( S_j ) = (1 - \\rho_\\xi) \\delta_{+1, S_j }  +  \\rho_\\xi \\delta_{-1, S_j }  \\; \\; .  $$\n",
    "\n",
    "The object $ {\\cal L} (\\mu)$ represents the set of $K$ non-zero elements on the row $\\mu$ of the code generator matrix ${\\cal G}$ (the one which adds redundancy), \n",
    "\n",
    "$$  {\\cal L} (\\mu) = \\langle i_1, i_2, ..., i_K \\rangle  \\; \\; .  $$\n",
    "\n",
    "The are $C$ non-zero elements per column on the matrix ${\\cal G}$:\n",
    "\n",
    "$$ \\sum_{\\mu : j \\in {\\cal L}(\\mu)} i_j = C \\; \\; ; \\; \\; \\forall j = 1, ..., K \\; \\; . $$\n",
    "\n",
    "The object $ {\\cal M} (j)$ represents the set of all index sets that contain $j$.\n",
    "\n",
    "After convergence of the iterative procedure, we can calculate the pseudo-posterior:\n",
    "\n",
    "$$ m_{j} = \\tanh \\left(  \\sum_{ \\nu \\in {\\cal M} (j) } \\tanh^{-1} \\left(  \\hat{m}_{\\nu j}  \\right)    + \\beta(\\rho_\\xi)  \\right)   \\; \\; ,  $$\n",
    "from which the Bayes optimal estimate is obtained\n",
    "$$ \\hat{\\xi}_j  = sign( m_j ) $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the variables of the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message lengh\n",
    "N = 10\n",
    "\n",
    "# Codeword lengh\n",
    "M = 20\n",
    "\n",
    "# Non-zero elements per row of the generation matrix\n",
    "K = 4\n",
    "\n",
    "# Number of messages\n",
    "n = 15\n",
    "\n",
    "# Noisy channel\n",
    "p = 0.3\n",
    "beta = 0.5*np.log( (1 - p) / p)\n",
    "\n",
    "# Message prior\n",
    "p_prior = 0.1\n",
    "beta_prior = 0.5*np.log( (1 - p_prior) / p_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating messages\n",
    "\n",
    "Each message is a $N$ dimensional vector. Generate a set of $n$ messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = torch.rand([n, N])\n",
    "\n",
    "#### -1 with probability p_prior\n",
    "#### +1 with probability 1 - p_prior\n",
    "\n",
    "message = 2* (random > p_prior).float() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [-1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.],\n",
      "        [-1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(message)\n",
    "message.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "Each message is encoded to a high dimensional vector ${\\bf J}^{(0)} \\in \\{ \\pm 1  \\}^M$ defined as \n",
    "\n",
    "$$   J^{(0)}_{\\langle i_1, i_2, ...., i_K \\rangle} = \\xi_1 \\xi_ 2 ... \\xi_K  \\; \\; ,$$\n",
    "\n",
    "where $M$ sets of $K \\in [ 1, ..., N]$ indexes are randomly chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = torch.randint(0, N, [M, K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From `encoding`, we construct the encoded message ${\\bf J}^{(0)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing\n",
    "J0 = torch.take(message[0], encoding).prod(dim=1)\n",
    "J0 = J0.unsqueeze(0)\n",
    "\n",
    "# Loop over all messages\n",
    "for j in range(1, message.shape[0]):\n",
    "    \n",
    "    J0_ = torch.take(message[j], encoding).prod(dim=1)\n",
    "    J0_ = J0_.unsqueeze(0)\n",
    "    \n",
    "    J0 = torch.cat((J0, J0_), dim= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
      "         -1.,  1., -1., -1., -1., -1.],\n",
      "        [ 1., -1., -1., -1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.,  1., -1.,\n",
      "          1.,  1.,  1., -1., -1., -1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [-1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
      "          1.,  1., -1., -1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1., -1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
      "          1., -1.,  1.,  1., -1., -1.],\n",
      "        [-1., -1., -1., -1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
      "          1.,  1.,  1.,  1., -1., -1.],\n",
      "        [ 1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
      "          1., -1.,  1., -1.,  1.,  1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 20])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(J0)\n",
    "J0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrupted version of the encoded set of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = torch.rand(J0.shape)\n",
    "\n",
    "## Flip tensor: -1 with probability p\n",
    "flip = 2*(random <= p).float() - 1\n",
    "\n",
    "## J corrupted version: element wise multiplication\n",
    "J = torch.mul(J0, flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,\n",
      "         -1.,  1., -1.,  1., -1.,  1.],\n",
      "        [-1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,\n",
      "         -1., -1.,  1.,  1., -1.,  1.],\n",
      "        [-1.,  1., -1.,  1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1., -1., -1.],\n",
      "        [-1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,\n",
      "         -1., -1., -1., -1., -1.,  1.],\n",
      "        [ 1.,  1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
      "          1., -1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,\n",
      "          1., -1., -1., -1.,  1., -1.],\n",
      "        [ 1., -1., -1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
      "         -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,\n",
      "          1., -1.,  1.,  1., -1.,  1.],\n",
      "        [-1., -1., -1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
      "          1.,  1., -1., -1.,  1., -1.],\n",
      "        [ 1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,\n",
      "         -1.,  1., -1., -1.,  1.,  1.],\n",
      "        [-1., -1., -1., -1., -1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,\n",
      "         -1.,  1.,  1.,  1., -1., -1.],\n",
      "        [ 1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,\n",
      "         -1.,  1., -1.,  1.,  1., -1.],\n",
      "        [ 1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1.,  1.,\n",
      "         -1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1., -1.,  1.,  1.],\n",
      "        [-1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,\n",
      "          1.,  1.,  1.,  1., -1., -1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 20])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(J)\n",
    "J.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating BP equations for one message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us focus in one received message to iterate the belief propagation equations.\n",
    "\n",
    "$$ \\hat{m}_{\\mu j} = \\tanh ( \\beta(\\rho) J_\\mu ) \\prod_{ l \\in {\\cal L} (\\mu) \\backslash j } m_{\\mu l}  \\; \\; ,  $$ \n",
    "\n",
    "$$ m_{\\mu j} = \\tanh \\left(  \\sum_{ \\nu \\in {\\cal M} (j) \\backslash \\mu} \\ \\tanh^{-1} \\left(  \\hat{m}_{\\nu j}  \\right) + \\beta(\\rho_\\xi)    \\right)   \\; \\; ,  $$  \n",
    "\n",
    "with $j = 1, ..., N$ and $\\mu = 1, ..., M$.\n",
    "\n",
    "We cal this message `J_`. We will worry later about a loop over all the received messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,\n",
      "        -1.,  1., -1.,  1., -1.,  1.])\n",
      "torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "J_ = J[0]\n",
    "print(J_)\n",
    "print(J_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random initialization of the beliefs $m_{\\mu l}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.rand(M, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8614, 0.7178, 0.3371, 0.2367, 0.1067, 0.5971, 0.4043, 0.2510, 0.5894,\n",
       "         0.4300],\n",
       "        [0.0165, 0.5987, 0.3994, 0.2361, 0.0408, 0.9143, 0.4325, 0.9045, 0.4464,\n",
       "         0.6526],\n",
       "        [0.6426, 0.9224, 0.6518, 0.6517, 0.0502, 0.3809, 0.4694, 0.8129, 0.9538,\n",
       "         0.7884],\n",
       "        [0.7773, 0.3005, 0.6068, 0.7846, 0.2382, 0.3705, 0.5191, 0.5133, 0.4931,\n",
       "         0.2246],\n",
       "        [0.9193, 0.4419, 0.2408, 0.3896, 0.0336, 0.9566, 0.9059, 0.2318, 0.9567,\n",
       "         0.0481],\n",
       "        [0.1630, 0.9127, 0.7098, 0.6659, 0.2184, 0.1310, 0.6776, 0.1232, 0.8820,\n",
       "         0.4901],\n",
       "        [0.8475, 0.1713, 0.4835, 0.6974, 0.3424, 0.8972, 0.8632, 0.9342, 0.1468,\n",
       "         0.3807],\n",
       "        [0.0481, 0.6787, 0.2059, 0.8278, 0.8066, 0.0966, 0.5245, 0.7966, 0.2402,\n",
       "         0.1617],\n",
       "        [0.7684, 0.3427, 0.9070, 0.4991, 0.2772, 0.5889, 0.8014, 0.0127, 0.4912,\n",
       "         0.6470],\n",
       "        [0.3333, 0.1253, 0.2880, 0.7476, 0.3486, 0.5392, 0.0883, 0.9343, 0.5379,\n",
       "         0.3550],\n",
       "        [0.1527, 0.9658, 0.0526, 0.1148, 0.5284, 0.2723, 0.4066, 0.3458, 0.7397,\n",
       "         0.3034],\n",
       "        [0.7314, 0.2023, 0.8082, 0.5329, 0.2827, 0.7885, 0.8335, 0.0409, 0.3238,\n",
       "         0.6677],\n",
       "        [0.4384, 0.0845, 0.5053, 0.4034, 0.7620, 0.6695, 0.9541, 0.0759, 0.5336,\n",
       "         0.2447],\n",
       "        [0.3681, 0.8912, 0.1353, 0.8789, 0.8169, 0.1896, 0.6834, 0.9100, 0.9585,\n",
       "         0.8792],\n",
       "        [0.8780, 0.1075, 0.4902, 0.5687, 0.8981, 0.1297, 0.7448, 0.6568, 0.7639,\n",
       "         0.9145],\n",
       "        [0.9842, 0.0678, 0.9322, 0.8849, 0.5356, 0.0618, 0.6785, 0.4697, 0.0926,\n",
       "         0.2882],\n",
       "        [0.4131, 0.8402, 0.1214, 0.4245, 0.5101, 0.1088, 0.3458, 0.7692, 0.6675,\n",
       "         0.0049],\n",
       "        [0.4759, 0.7655, 0.8854, 0.5951, 0.0705, 0.2157, 0.0479, 0.6964, 0.8895,\n",
       "         0.6402],\n",
       "        [0.9772, 0.0028, 0.2308, 0.4180, 0.1741, 0.6795, 0.0244, 0.5041, 0.8435,\n",
       "         0.0724],\n",
       "        [0.8895, 0.9080, 0.9966, 0.2351, 0.4388, 0.6242, 0.3225, 0.5305, 0.3947,\n",
       "         0.3091]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize an empty tensor to represent $\\hat{m}_{\\mu l}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_hat = torch.empty(M, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  8.6047e-05,\n",
       "          1.6707e-19,  1.9661e-13,  4.5755e-41,  1.9411e-13,  4.5755e-41],\n",
       "        [-3.2150e-11,  9.6386e-37,  1.9404e-13,  4.5755e-41,  1.3593e-43,\n",
       "          0.0000e+00, -3.5438e+00,  3.0719e-41, -3.5352e+00,  3.0719e-41],\n",
       "        [ 1.4013e-45,  0.0000e+00,  3.4363e-07,  2.2088e-26,  1.9402e-13,\n",
       "          4.5755e-41,  1.8925e-13,  4.5755e-41,  3.7998e-20,  1.0535e-17],\n",
       "        [ 4.6243e-44,  0.0000e+00, -3.5355e+00,  3.0719e-41, -3.5354e+00,\n",
       "          3.0719e-41,  6.5020e-43,  0.0000e+00,  1.5695e-43,  0.0000e+00],\n",
       "        [-3.5353e+00,  3.0719e-41,  2.7569e-13,  4.5755e-41,  1.9477e-13,\n",
       "          4.5755e-41,  7.2113e-19, -2.8305e+19,  1.8969e-13,  4.5755e-41],\n",
       "        [ 1.9478e-13,  4.5755e-41, -6.6884e+24, -1.0948e+27,  4.2997e-13,\n",
       "          4.5755e-41,  3.9595e-13,  4.5755e-41,  4.8372e-12,  2.2151e+36],\n",
       "        [ 4.1639e-13,  4.5755e-41,  1.9412e-13,  4.5755e-41,  2.9086e+19,\n",
       "         -3.9255e+35,  4.8430e-41,  0.0000e+00, -3.5437e+00,  3.0719e-41],\n",
       "        [ 1.8042e-12,  4.5755e-41,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  2.8054e-05, -5.8720e+18,  4.6243e-44,  0.0000e+00],\n",
       "        [-3.5354e+00,  3.0719e-41, -3.5354e+00,  3.0719e-41,  1.1210e-43,\n",
       "          0.0000e+00,  8.9683e-44,  0.0000e+00, -3.5352e+00,  3.0719e-41],\n",
       "        [ 1.9147e-13,  4.5755e-41,  1.9105e-13,  4.5755e-41, -2.4508e-03,\n",
       "         -3.8639e-24,  1.9083e-13,  4.5755e-41,  1.9157e-13,  4.5755e-41],\n",
       "        [-1.1632e-05, -3.8878e+21,  9.1084e-44,  0.0000e+00,  1.8042e-12,\n",
       "          4.5755e-41, -3.5352e+00,  3.0719e-41,  0.0000e+00,  0.0000e+00],\n",
       "        [ 4.6243e-44,  0.0000e+00, -3.5354e+00,  3.0719e-41, -3.5354e+00,\n",
       "          3.0719e-41,  2.9147e-43,  0.0000e+00,  1.1210e-43,  0.0000e+00],\n",
       "        [-3.5353e+00,  3.0719e-41,  1.8622e-13,  4.5755e-41, -1.9283e+29,\n",
       "         -1.5606e+01,  1.9147e-13,  4.5755e-41,  1.8702e-13,  4.5755e-41],\n",
       "        [ 2.3746e+19, -2.9079e-22,  2.0712e-13,  4.5755e-41,  1.8956e-13,\n",
       "          4.5755e-41, -5.8589e+27,  1.0788e+21,  2.4803e-43,  0.0000e+00],\n",
       "        [-3.5356e+00,  3.0719e-41,  1.8042e-12,  4.5755e-41,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00, -4.6930e+24, -2.7506e-17],\n",
       "        [ 3.8262e-13,  4.5755e-41,  1.8706e-13,  4.5755e-41,  9.3006e-27,\n",
       "         -6.8216e+08,  3.8458e-13,  4.5755e-41,  1.3593e-43,  0.0000e+00],\n",
       "        [-3.5354e+00,  3.0719e-41, -3.5354e+00,  3.0719e-41,  1.4013e-45,\n",
       "          0.0000e+00, -2.3815e+34,  7.2313e-31,  3.8222e-13,  4.5755e-41],\n",
       "        [ 3.8514e-13,  4.5755e-41, -7.2024e+22,  6.1784e-37,  4.6243e-44,\n",
       "          0.0000e+00,  1.8042e-12,  4.5755e-41, -3.5354e+00,  3.0719e-41],\n",
       "        [ 6.5020e-43,  0.0000e+00,  1.5695e-43,  0.0000e+00, -3.5354e+00,\n",
       "          3.0719e-41,  3.8189e-13,  4.5755e-41,  3.8516e-13,  4.5755e-41],\n",
       "        [ 8.3873e-26,  1.1021e-21,  1.7357e-13,  4.5755e-41,  3.8511e-13,\n",
       "          4.5755e-41,  5.5007e-31,  1.2200e-05,  1.7566e-13,  4.5755e-41]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to calculate $\\hat{m}_{\\mu j}$.\n",
    "\n",
    "$$ \\hat{m}_{\\mu j} = \\tanh ( \\beta(\\rho) J_\\mu ) \\prod_{ l \\in {\\cal L} (\\mu) \\backslash j } m_{\\mu l}  \\; \\; ,  $$ \n",
    "\n",
    "This first implementation has two `for` loops. This is potentially harmful if one cares about efficienty. We obviously do, but since we are just beginning, lets go on like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mu in range(M):\n",
    "    for j in range(N):\n",
    "          \n",
    "        # Keep only L(mu) which a are different of j\n",
    "        index_no_j = torch.nonzero(encoding[mu] != j).squeeze()\n",
    "        L_no_j = encoding[mu][index_no_j]\n",
    "        \n",
    "        # Message update        \n",
    "        m_hat[mu, j] = torch.tanh( beta* J_[mu])*torch.take(m[mu], L_no_j).prod(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to implement:\n",
    "\n",
    "$$ m_{\\mu j} = \\tanh \\left(  \\sum_{ \\nu \\in {\\cal M} (j) \\backslash \\mu} \\ \\tanh^{-1} \\left(  \\hat{m}_{\\nu j}  \\right) + \\beta(\\rho_\\xi)     \\right)  \\; \\; ,  $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(N):\n",
    "    \n",
    "    for mu in range(M):\n",
    "        \n",
    "        M_set = torch.where(encoding == j)[0]\n",
    "        \n",
    "        M_set_no_mu = M_set[torch.nonzero(M_set != mu).squeeze()]\n",
    "        \n",
    "        m[mu, j] = torch.tanh(torch.take(np.arctanh(m_hat[:, j]), M_set_no_mu).sum() + beta_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8000, 0.8000, 0.8000,  ..., 0.8000, 0.8000, 0.8000],\n",
       "        [0.8000, 0.8000, 0.8000,  ..., 0.8000, 0.8000, 0.8000],\n",
       "        [0.8000, 0.8000, 0.8000,  ..., 0.8000, 0.8000, 0.8000],\n",
       "        ...,\n",
       "        [0.8000, 0.8000, 0.8000,  ..., 0.8000, 0.8000, 0.8000],\n",
       "        [0.8000, 0.8000, 0.8000,  ..., 0.8000, 0.8000, 0.8000],\n",
       "        [0.8000, 0.8000, 0.8000,  ..., 0.8000, 0.8000, 0.8000]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to implement the pseudo-posterior, which is calculated after convergence of the messages above:\n",
    "\n",
    "$$ m_{j} = \\tanh \\left(  \\sum_{ \\nu \\in {\\cal M} (j) } \\tanh^{-1} \\left(  \\hat{m}_{\\nu j}  \\right)    + \\beta(\\rho_\\xi)  \\right)   \\; \\; ,  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_bayes = []\n",
    "\n",
    "for j in range(N):\n",
    "    \n",
    "    M_set = torch.where(encoding == j)[0]\n",
    "       \n",
    "    m_j = torch.tanh(torch.take(np.arctanh(m_hat[:, j]), M_set).sum() + beta_prior)\n",
    "    \n",
    "    m_bayes.append(m_j.item())\n",
    "            \n",
    "m_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m_bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sign(m_bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering all message iterations on functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_to_mhat(N, M, J_, m, beta, encoding):\n",
    "    \n",
    "    m_hat = torch.empty(M, N)\n",
    "    \n",
    "    for mu in range(M):\n",
    "        for j in range(N):\n",
    "                     \n",
    "            # Keep only L(mu) which a are different of j\n",
    "            index_no_j = torch.nonzero(encoding[mu] != j).squeeze()\n",
    "            L_no_j = encoding[mu][index_no_j]\n",
    "        \n",
    "            # Message update        \n",
    "            m_hat[mu, j] = torch.tanh( beta* J_[mu])*torch.take(m[mu], L_no_j).prod(dim=0)\n",
    "            \n",
    "    return m_hat\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "\n",
    "def mhat_to_m(N, M, m_hat, beta_prior, encoding):\n",
    "    \n",
    "    m = torch.empty(M, N)\n",
    "    \n",
    "    for j in range(N):\n",
    "        \n",
    "        for mu in range(M):\n",
    "            \n",
    "            M_set = torch.where(encoding == j)[0]\n",
    "        \n",
    "            M_set_no_mu = M_set[torch.nonzero(M_set != mu).squeeze()]\n",
    "            \n",
    "            m[mu, j] = torch.tanh(torch.take(np.arctanh(m_hat[:, j]), M_set_no_mu).sum() + beta_prior)\n",
    "            \n",
    "    return m\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "\n",
    "def m_bayes(N, m_hat_final, beta_prior, encoding):\n",
    "    \n",
    "    m_bayes = []\n",
    "\n",
    "    for j in range(N):\n",
    "           \n",
    "        M_set = torch.where(encoding == j)[0]\n",
    "  \n",
    "        m_j = torch.tanh(torch.take(np.arctanh(m_hat_final[:, j]), M_set).sum() + beta_prior)\n",
    "    \n",
    "        m_bayes.append(m_j.item())\n",
    "        \n",
    "    return m_bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we construct a function for the iterative decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BP_LDPC(N, M, J_, beta, beta_prior, encoding, message, num_it= 100, verbose= 1):\n",
    "     \n",
    "    m_hat = torch.rand(M, N)\n",
    "    m = torch.empty(M, N)\n",
    "    \n",
    "    for j in range(num_it):\n",
    "        \n",
    "        print('--it = %d' % j)\n",
    "              \n",
    "        m = mhat_to_m(N, M, m_hat, beta_prior, encoding)\n",
    "        m_hat = m_to_mhat(N, M, J_, m, beta, encoding)\n",
    "        \n",
    "        ## Monitoring performace\n",
    "        if (j % verbose) == 0:\n",
    "            m_ = m_bayes(N, m_hat, beta_prior, encoding)\n",
    "            print('overlap= ', torch.dot(message, torch.Tensor(np.sign(m_))).item() / N)\n",
    "        \n",
    "    m_final = m_bayes(N, m_hat, beta_prior, encoding)\n",
    "    \n",
    "    return np.sign(m_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--it = 0\n",
      "overlap=  0.76\n",
      "--it = 1\n",
      "overlap=  0.76\n",
      "--it = 2\n",
      "overlap=  0.76\n",
      "--it = 3\n",
      "overlap=  0.76\n",
      "--it = 4\n",
      "overlap=  0.76\n",
      "--it = 5\n",
      "overlap=  0.76\n",
      "--it = 6\n",
      "overlap=  0.76\n",
      "--it = 7\n",
      "overlap=  0.76\n",
      "--it = 8\n",
      "overlap=  0.76\n",
      "--it = 9\n",
      "overlap=  0.76\n",
      "--it = 10\n",
      "overlap=  0.76\n",
      "--it = 11\n",
      "overlap=  0.76\n",
      "--it = 12\n",
      "overlap=  0.76\n",
      "--it = 13\n",
      "overlap=  0.76\n",
      "--it = 14\n",
      "overlap=  0.76\n",
      "--it = 15\n",
      "overlap=  0.76\n",
      "--it = 16\n",
      "overlap=  0.76\n",
      "--it = 17\n",
      "overlap=  0.76\n",
      "--it = 18\n",
      "overlap=  0.76\n",
      "--it = 19\n",
      "overlap=  0.76\n"
     ]
    }
   ],
   "source": [
    "opt_dec_Bayes = BP_LDPC(N, M, J_, beta, beta_prior, encoding, message[0], num_it= 20, verbose= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. It is still slow (we will worrie about this latter), but it appears to work.\n",
    "\n",
    "Observe that we arbitrarily consider a certain `num_it`. Naturally, a important question remains: how do we monitor the convergence of BP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick test on previous codes and messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message lengh\n",
    "N = 250\n",
    "\n",
    "# Codeword lengh\n",
    "M = 500\n",
    "\n",
    "# Non-zero elements per row of the generation matrix\n",
    "K = 4\n",
    "\n",
    "# Number of messages\n",
    "n = 100\n",
    "\n",
    "# Noisy channel\n",
    "p = 0.3\n",
    "beta = 0.5*np.log( (1 - p) / p)\n",
    "\n",
    "# Message prior\n",
    "p_prior = 0.01\n",
    "beta_prior = 0.5*np.log( (1 - p_prior) / p_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = torch.load('codes/code_N_250_M_500_K_4_p_03_p_prior_001_j_0.pt')\n",
    "message = torch.load('codes/message_N_250_M_500_K_4_p_03_p_prior_001.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  ...,  1., -1.,  1.],\n",
       "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
       "        ...,\n",
       "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  ...,  1., -1.,  1.],\n",
      "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
      "        ...,\n",
      "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 250])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(message)\n",
    "message.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we made a mistake saving the codes. We have actually saved the messages. That is a problem. For now, let us generate a new code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 19,  14, 131, 126],\n",
       "        [  0,   0, 169, 179],\n",
       "        [226, 164, 236, 118],\n",
       "        ...,\n",
       "        [ 47, 104, 136, 229],\n",
       "        [173, 132,   4, 112],\n",
       "        [ 41, 106,  31, 195]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding  = torch.randint(0, N, [M, K])\n",
    "encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing\n",
    "J0 = torch.take(message[0], encoding).prod(dim=1)\n",
    "J0 = J0.unsqueeze(0)\n",
    "\n",
    "for j in range(1, message.shape[0]):\n",
    "    \n",
    "    J0_ = torch.take(message[j], encoding).prod(dim=1)\n",
    "    J0_ = J0_.unsqueeze(0)\n",
    "    \n",
    "    J0 = torch.cat((J0, J0_), dim= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 500])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(J0)\n",
    "J0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corrupted version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = torch.rand(J0.shape)\n",
    "\n",
    "## Flip tensor: -1 with probability p\n",
    "flip = 2*(random <= p).float() - 1\n",
    "\n",
    "## J corrupted version: element wise multiplication\n",
    "J = torch.mul(J0, flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1., -1.,  ..., -1., -1.,  1.],\n",
      "        [ 1.,  1., -1.,  ..., -1., -1., -1.],\n",
      "        [ 1.,  1., -1.,  ..., -1., -1.,  1.],\n",
      "        ...,\n",
      "        [-1., -1., -1.,  ..., -1., -1.,  1.],\n",
      "        [-1., -1.,  1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 500])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(J)\n",
    "J.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([250])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "500\n",
      "torch.Size([500, 4])\n",
      "torch.Size([100, 500])\n",
      "torch.Size([100, 250])\n"
     ]
    }
   ],
   "source": [
    "print(N)\n",
    "print(M)\n",
    "print(encoding.shape)\n",
    "print(J.shape)\n",
    "print(message.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----message 0\n",
      "--it = 0\n",
      "overlap=  0.648\n",
      "--it = 1\n",
      "overlap=  0.992\n",
      "--it = 2\n",
      "overlap=  0.808\n",
      "--it = 3\n",
      "overlap=  0.992\n",
      "--it = 4\n",
      "overlap=  0.832\n",
      "--it = 5\n",
      "overlap=  0.992\n",
      "--it = 6\n",
      "overlap=  0.848\n",
      "--it = 7\n",
      "overlap=  0.992\n",
      "--it = 8\n",
      "overlap=  0.864\n",
      "--it = 9\n",
      "overlap=  0.992\n",
      "----message 1\n",
      "--it = 0\n",
      "overlap=  0.656\n",
      "--it = 1\n",
      "overlap=  0.976\n",
      "--it = 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-dbce05a40616>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----message %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mopt_dec_Bayes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBP_LDPC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moverlap_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_dec_Bayes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-47f5071fc012>\u001b[0m in \u001b[0;36mBP_LDPC\u001b[0;34m(N, M, J_, beta, beta_prior, encoding, message, num_it, verbose)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--it = %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmhat_to_m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mm_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_to_mhat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-080c605b59ce>\u001b[0m in \u001b[0;36mmhat_to_m\u001b[0;34m(N, M, m_hat, beta_prior, encoding)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mM_set_no_mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_set\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marctanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_set_no_mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta_prior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "overlap_list = []\n",
    "\n",
    "for k in range(int(J.shape[0] / 10 )):\n",
    "    \n",
    "    print('----message %d' % k)\n",
    "       \n",
    "    opt_dec_Bayes = BP_LDPC(N, M, J[k], beta, beta_prior, encoding, message[k], num_it= 10, verbose= 1)\n",
    "    \n",
    "    overlap_list.append(opt_dec_Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over different noise parameters to chech consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message lengh\n",
    "N = 250\n",
    "\n",
    "# Codeword lengh\n",
    "M = 500\n",
    "\n",
    "# Non-zero elements per row of the generation matrix\n",
    "K = 4\n",
    "\n",
    "# Number of messages\n",
    "n = 100\n",
    "\n",
    "# Noisy channel\n",
    "p = np.array([0.1, 0.2, 0.225, 0.25, 0.275, 0.3, 0.325, 0.35, 0.375, 0.4, 0.45, 0.495])\n",
    "beta = 0.5*np.log( (1 - p) / p)\n",
    "\n",
    "# Message prior\n",
    "p_prior = 0.01\n",
    "beta_prior = 0.5*np.log( (1 - p_prior) / p_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = torch.rand([n, N])\n",
    "\n",
    "#### -1 with probability p_prior\n",
    "#### +1 with probability 1 - p_prior\n",
    "\n",
    "message = 2* (random > p_prior).float() - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = torch.randint(0, N, [M, K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing\n",
    "J0 = torch.take(message[0], encoding).prod(dim=1)\n",
    "J0 = J0.unsqueeze(0)\n",
    "\n",
    "# Loop over all messages\n",
    "for j in range(1, message.shape[0]):\n",
    "    \n",
    "    J0_ = torch.take(message[j], encoding).prod(dim=1)\n",
    "    J0_ = J0_.unsqueeze(0)\n",
    "    \n",
    "    J0 = torch.cat((J0, J0_), dim= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ p =  0.1\n",
      "----message 0\n",
      "--it = 0\n"
     ]
    }
   ],
   "source": [
    "random = torch.rand(J0.shape)\n",
    "\n",
    "p_list = []\n",
    "overlap_list = []\n",
    "\n",
    "for p_ in p:\n",
    "    \n",
    "    print('------ p = ', p_)\n",
    "    \n",
    "    p_list.append(p_)\n",
    "    \n",
    "    beta_ = 0.5*np.log( (1 - p_) / p_)\n",
    "    \n",
    "    ## Flip tensor: -1 with probability p\n",
    "    flip = 2*(random <= p_).float() - 1\n",
    "    ## J corrupted version: element wise multiplication\n",
    "    J = torch.mul(J0, flip)\n",
    "    ##\n",
    "    overlap_list_p = []\n",
    "\n",
    "    for k in range(int(J.shape[0] / 10 )):\n",
    "    \n",
    "        print('----message %d' % k)\n",
    "       \n",
    "        opt_dec_Bayes = BP_LDPC(N, M, J[k], beta_, beta_prior, encoding, message[k], num_it= 10, verbose= 1)\n",
    "    \n",
    "        overlap_list_p.append(opt_dec_Bayes)\n",
    "        \n",
    "    overlap_list.append(overlap_list_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
